{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat and Refinement Procedure\n",
    "In this notebook, we will concat the data and do some additional refinement process.\n",
    "The procedures consists of following things.\n",
    "- before concat\n",
    "    1. GCS data refinement: outlier deletion, concatenation\n",
    "    2. time error deletion : for icu module data, exceeding IT OT data deletion and hosp data no deletion \n",
    "    3. rarely observed feature identification: delete the features whose missing rate larger than 75%\n",
    "    4. main variable not observed cohort deletion \n",
    "- in concat\n",
    "    1. concat into admission\n",
    "    2. hosp urine data have to be concated for only when there is no urine data for total cohort\n",
    "    3. SOFA calculation, shock diagnosis\n",
    "- after concat\n",
    "    1. weight, height consistency error\n",
    "    2. shock diagnosis time statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from warnings import simplefilter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "simplefilter(action=\"ignore\", category=pd.errors.DtypeWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from sepsis_preprocessing import data_concatenation\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. before concat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 GCS refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [str('processed_data/sepsis/%s_R.csv' %i) for i in ['omr', 'LE', 'CE', 'IE', 'OE', 'PE']]\n",
    "df = pd.read_csv(dirs[2])\n",
    "df.charttime = pd.to_datetime(df.charttime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>itemid</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [subject_id, hadm_id, stay_id, charttime, storetime, itemid, valuenum, valueuom]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier deletion\n",
    "tmp_itemid = [220739,223900,223901]\n",
    "drop_idx = []\n",
    "for ii in tmp_itemid:\n",
    "    tmp_cond = df.itemid == ii\n",
    "    part_df = df.loc[tmp_cond]\n",
    "    \n",
    "    if ii == 220739:\n",
    "        lb = 1\n",
    "        ub = 4\n",
    "    elif ii == 223900:\n",
    "        lb = 1\n",
    "        ub = 5\n",
    "    else:\n",
    "        lb = 1\n",
    "        ub = 6\n",
    "    \n",
    "    tmp_cond = (part_df.valuenum > ub) | (part_df.valuenum < lb)\n",
    "    \n",
    "    drop_idx += tmp_cond.index[tmp_cond].tolist()\n",
    "        \n",
    "df.loc[drop_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26622/26622 [56:02<00:00,  7.92it/s]  \n",
      "100%|██████████| 26449/26449 [02:07<00:00, 207.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# GCS concat\n",
    "tmp_data = []\n",
    "for stay in tqdm(df.stay_id.unique()):\n",
    "    tmp_cond = (df.stay_id == stay) & (df.itemid.isin(tmp_itemid))\n",
    "    part_df = df.loc[tmp_cond]\n",
    "\n",
    "    if part_df.shape[0] == 0:\n",
    "        continue\n",
    "    ct_list = part_df.charttime.unique()\n",
    "    for ct in ct_list:\n",
    "        tmp_cond = (part_df.charttime == ct)\n",
    "        tmp_list = part_df.iloc[0, 0:3].tolist()+[ct]\n",
    "        tmp_list += [part_df.loc[tmp_cond&(part_df.itemid==tmp_itemid[i]), 'valuenum'].to_numpy()[0] if part_df.loc[tmp_cond&(part_df.itemid==tmp_itemid[i]), 'valuenum'].shape[0] == 1 else np.nan for i in range(3)]\n",
    "        tmp_data.append(tmp_list)\n",
    "     \n",
    "tmp_data = pd.DataFrame(tmp_data, columns=['subject_id', 'hadm_id', 'stay_id', 'charttime', 'eye', 'verbal', 'motor'])\n",
    "\n",
    "for stay in tqdm(tmp_data.stay_id.unique()):\n",
    "    tmp_cond = (tmp_data.stay_id == stay)\n",
    "    part_df = tmp_data.loc[tmp_cond]\n",
    "\n",
    "    tmp_data.loc[tmp_cond] = part_df.ffill().bfill()\n",
    "\n",
    "tmp_data['itemid'] = sum(tmp_itemid)\n",
    "tmp_data['valuenum'] = tmp_data.loc[:, ('eye', 'verbal', 'motor')].sum(axis=1)\n",
    "tmp_data['valueuom'] = np.nan\n",
    "\n",
    "df = pd.concat([df, tmp_data.loc[:, list(set(tmp_data.columns) - set(tmp_data.columns[4:7]))]], axis=0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCS refined version of CE saving\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df = df.drop(tmp_cond[tmp_cond].index)\n",
    "df = df.sort_values(['stay_id', 'charttime', 'itemid'])\n",
    "df.loc[:, list(set(df.columns) - set(['storetime']))].to_csv('processed_data/sepsis/CE_R.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ('subject_id', 'hadm_id', 'stay_id', 'charttime', 'itemid', 'valuenum', 'valueuom')].to_csv('processed_data/sepsis/CE_R.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 time error handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "time error handling criteria\n",
    "1. lab values: exceeding IT, OT will be deleted\n",
    "2. vaso, fluid, ventilators: exceeding IT and OT at the same time will be deleted. \n",
    "\n",
    "=> therefore, LE and OMR will not be the interests of this sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [str('processed_data/sepsis/%s_R.csv' %i) for i in ['omr', 'LE', 'CE', 'IE', 'OE', 'PE']]\n",
    "icustays = pd.read_csv('processed_data/sepsis/icustays_wsusinf.csv')\n",
    "icustays.intime = pd.to_datetime(icustays.intime)\n",
    "icustays.outtime = pd.to_datetime(icustays.outtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26622/26622 [06:20<00:00, 70.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2174-09-29 12:09:00\n",
      "outtime   2174-10-01 03:26:10\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "12466550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26446/26446 [01:52<00:00, 235.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2129-04-06 00:25:00\n",
      "outtime   2129-04-08 21:02:55\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "10007928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25494/25494 [01:26<00:00, 293.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2188-06-05 23:38:19\n",
      "outtime   2188-06-08 00:32:17\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "16235911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12893/12893 [00:23<00:00, 540.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2191-06-23 22:57:47\n",
      "outtime   2191-06-24 09:22:22\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "10501162\n"
     ]
    }
   ],
   "source": [
    "# 0 hours\n",
    "tmp_data = []\n",
    "for data_dir in dirs[2:]:\n",
    "    drop_idx = []\n",
    "    df = pd.read_csv(data_dir)\n",
    "    try:\n",
    "        df.charttime = pd.to_datetime(df.charttime)\n",
    "        cond_ct = 1\n",
    "    except:\n",
    "        df.starttime = pd.to_datetime(df.starttime)\n",
    "        df.endtime = pd.to_datetime(df.endtime)\n",
    "        cond_ct = 0\n",
    "        \n",
    "    td_list = []\n",
    "    for stay in tqdm(df.stay_id.unique()):\n",
    "        tmp_cond = icustays.stay_id == stay\n",
    "        it, ot = icustays.loc[tmp_cond, ('intime', 'outtime')].reset_index(drop=True).loc[0]\n",
    "\n",
    "        tmp_cond = df.stay_id == stay\n",
    "        part_df = df.loc[tmp_cond]\n",
    "\n",
    "        if cond_ct == 1:\n",
    "            tmp_cond = (part_df.charttime > ot) | (part_df.charttime < it)\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.charttime > ot), 'charttime'] - ot)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((it - part_df.loc[(part_df.charttime < it), 'charttime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "        else:\n",
    "            tmp_cond = (part_df.starttime > ot) | (part_df.endtime < it)\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.starttime > ot), 'starttime'] - ot)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((it - part_df.loc[(part_df.endtime < it), 'endtime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "    print(icustays.loc[icustays.stay_id == df.loc[drop_idx, 'stay_id'][drop_idx[0]], ('intime', 'outtime')].reset_index(drop=True).loc[0])\n",
    "    print(df.loc[drop_idx[0]].reset_index(drop=True).loc[0])\n",
    "    tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n",
    "    df = df.drop(drop_idx).reset_index(drop=True)\n",
    "    df.to_csv(data_dir[:-5]+'TEH_v1.csv', index=False)\n",
    "\n",
    "pd.DataFrame(tmp_data, columns=['df', 'b4_drop', 'a_drop', 'b4_stay', 'drop_stays', 'drop_iis', 'drop_td']).to_csv('tmp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26622/26622 [06:23<00:00, 69.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2174-09-29 12:09:00\n",
      "outtime   2174-10-01 03:26:10\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               12466550\n",
      "1               23998182\n",
      "2               30000153\n",
      "3    2174-10-04 19:14:00\n",
      "4                 220179\n",
      "5                  119.0\n",
      "6                   mmHg\n",
      "Name: 277, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26446/26446 [01:54<00:00, 231.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2142-01-17 09:13:46\n",
      "outtime   2142-01-25 01:26:14\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0                10449408\n",
      "1                22698294\n",
      "2                30983111\n",
      "3     2142-01-14 23:00:00\n",
      "4     2142-01-14 23:01:00\n",
      "5                  226452\n",
      "6                   120.0\n",
      "7                      ml\n",
      "8                     NaN\n",
      "9                     NaN\n",
      "10                   80.4\n",
      "Name: 150801, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25494/25494 [01:27<00:00, 290.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2127-07-01 07:20:08\n",
      "outtime   2127-07-03 16:15:29\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               12407894\n",
      "1               20375008\n",
      "2               30014984\n",
      "3    2127-07-05 18:00:00\n",
      "4                 226559\n",
      "5                  300.0\n",
      "6                     ml\n",
      "Name: 3464, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12893/12893 [00:24<00:00, 525.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2115-02-13 00:23:12\n",
      "outtime   2115-02-15 17:28:17\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               18083893\n",
      "1               27616048\n",
      "2               31068539\n",
      "3    2115-02-16 21:47:00\n",
      "4    2115-02-16 22:28:00\n",
      "5                 225792\n",
      "6                   41.0\n",
      "Name: 13509, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1 hour \n",
    "tmp_data = []\n",
    "for data_dir in dirs[2:]:\n",
    "    drop_idx = []\n",
    "    df = pd.read_csv(data_dir)\n",
    "    try:\n",
    "        df.charttime = pd.to_datetime(df.charttime)\n",
    "        cond_ct = 1\n",
    "    except:\n",
    "        df.starttime = pd.to_datetime(df.starttime)\n",
    "        df.endtime = pd.to_datetime(df.endtime)\n",
    "        cond_ct = 0\n",
    "        \n",
    "    td_list = []\n",
    "    for stay in tqdm(df.stay_id.unique()):\n",
    "        tmp_cond = icustays.stay_id == stay\n",
    "        it, ot = icustays.loc[tmp_cond, ('intime', 'outtime')].reset_index(drop=True).loc[0]\n",
    "\n",
    "        tmp_cond = df.stay_id == stay\n",
    "        part_df = df.loc[tmp_cond]\n",
    "\n",
    "        if cond_ct == 1:\n",
    "            tmp_cond = (part_df.charttime > (ot+datetime.timedelta(days=1))) | (part_df.charttime < (it-datetime.timedelta(days=1)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.charttime > (ot+datetime.timedelta(days=1))), 'charttime'] - ot)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((it - part_df.loc[(part_df.charttime < (it-datetime.timedelta(days=1))), 'charttime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "        else:\n",
    "            tmp_cond = (part_df.starttime > (ot+datetime.timedelta(days=1))) | (part_df.endtime < (it-datetime.timedelta(days=1)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.starttime > (ot+datetime.timedelta(days=1))), 'starttime'] - ot)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((it - part_df.loc[(part_df.endtime < (it-datetime.timedelta(days=1))), 'endtime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "    print(icustays.loc[icustays.stay_id == df.loc[drop_idx, 'stay_id'][drop_idx[0]], ('intime', 'outtime')].reset_index(drop=True).loc[0])\n",
    "    print(df.loc[drop_idx[0]].reset_index(drop=True))\n",
    "    tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n",
    "    df = df.drop(drop_idx).reset_index(drop=True)\n",
    "    df.to_csv(data_dir[:-5]+'TEH_v2.csv', index=False)\n",
    "\n",
    "pd.DataFrame(tmp_data, columns=['df', 'b4_drop', 'a_drop', 'b4_stay', 'drop_stays', 'drop_iis', 'drop_td']).to_csv('tmp_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26622/26622 [06:23<00:00, 69.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2174-09-29 12:09:00\n",
      "outtime   2174-10-01 03:26:10\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               12466550\n",
      "1               23998182\n",
      "2               30000153\n",
      "3    2174-10-04 19:14:00\n",
      "4                 220179\n",
      "5                  119.0\n",
      "6                   mmHg\n",
      "Name: 277, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26446/26446 [01:53<00:00, 233.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2142-01-17 09:13:46\n",
      "outtime   2142-01-25 01:26:14\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0                10449408\n",
      "1                22698294\n",
      "2                30983111\n",
      "3     2142-01-14 23:00:00\n",
      "4     2142-01-14 23:01:00\n",
      "5                  226452\n",
      "6                   120.0\n",
      "7                      ml\n",
      "8                     NaN\n",
      "9                     NaN\n",
      "10                   80.4\n",
      "Name: 150801, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25494/25494 [01:26<00:00, 293.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2127-07-01 07:20:08\n",
      "outtime   2127-07-03 16:15:29\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               12407894\n",
      "1               20375008\n",
      "2               30014984\n",
      "3    2127-07-05 18:00:00\n",
      "4                 226559\n",
      "5                  300.0\n",
      "6                     ml\n",
      "Name: 3464, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12893/12893 [00:24<00:00, 530.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2192-06-29 14:40:21\n",
      "outtime   2192-07-03 23:27:24\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               19651093\n",
      "1               26488509\n",
      "2               30067309\n",
      "3    2192-05-25 18:40:00\n",
      "4    2192-06-08 15:59:00\n",
      "5                 225792\n",
      "6                19999.0\n",
      "Name: 16022, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2 hour\n",
    "tmp_data = []\n",
    "for data_dir in dirs[2:]:\n",
    "    drop_idx = []\n",
    "    df = pd.read_csv(data_dir)\n",
    "    try:\n",
    "        df.charttime = pd.to_datetime(df.charttime)\n",
    "        cond_ct = 1\n",
    "    except:\n",
    "        df.starttime = pd.to_datetime(df.starttime)\n",
    "        df.endtime = pd.to_datetime(df.endtime)\n",
    "        cond_ct = 0\n",
    "        \n",
    "    td_list = []\n",
    "    for stay in tqdm(df.stay_id.unique()):\n",
    "        tmp_cond = icustays.stay_id == stay\n",
    "        it, ot = icustays.loc[tmp_cond, ('intime', 'outtime')].reset_index(drop=True).loc[0]\n",
    "\n",
    "        tmp_cond = df.stay_id == stay\n",
    "        part_df = df.loc[tmp_cond]\n",
    "\n",
    "        if cond_ct == 1:\n",
    "            tmp_cond = (part_df.charttime > (ot+datetime.timedelta(days=2))) | (part_df.charttime < (it-datetime.timedelta(days=2)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.charttime > (ot+datetime.timedelta(days=2))), 'charttime'] - ot)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((it - part_df.loc[(part_df.charttime < (it-datetime.timedelta(days=2))), 'charttime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "        else:\n",
    "            tmp_cond = (part_df.starttime > (ot+datetime.timedelta(days=2))) | (part_df.endtime < (it-datetime.timedelta(days=2)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.starttime > (ot+datetime.timedelta(days=2))), 'starttime'] - ot)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((it - part_df.loc[(part_df.endtime < (it-datetime.timedelta(days=2))), 'endtime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "    print(icustays.loc[icustays.stay_id == df.loc[drop_idx, 'stay_id'][drop_idx[0]], ('intime', 'outtime')].reset_index(drop=True).loc[0])\n",
    "    print(df.loc[drop_idx[0]].reset_index(drop=True))\n",
    "    tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n",
    "    df = df.drop(drop_idx).reset_index(drop=True)\n",
    "    df.to_csv(data_dir[:-5]+'TEH_v3.csv', index=False)\n",
    "\n",
    "pd.DataFrame(tmp_data, columns=['df', 'b4_drop', 'a_drop', 'b4_stay', 'drop_stays', 'drop_iis', 'drop_td']).to_csv('tmp_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = pd.read_csv('hosp/admissions.csv')\n",
    "admissions.admittime = pd.to_datetime(admissions.admittime)\n",
    "admissions.dischtime = pd.to_datetime(admissions.dischtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26622/26622 [06:39<00:00, 66.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2185-04-19 22:59:00\n",
      "outtime   2185-05-07 19:05:25\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               13077594\n",
      "1               22574617\n",
      "2               30056766\n",
      "3    2185-05-09 22:00:00\n",
      "4                 220228\n",
      "5                    7.6\n",
      "6                   g/dl\n",
      "Name: 139742, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26446/26446 [02:03<00:00, 213.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2116-08-27 19:15:00\n",
      "outtime   2116-09-03 15:04:09\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0                11320106\n",
      "1                21001406\n",
      "2                33963040\n",
      "3     2116-09-02 16:50:00\n",
      "4     2116-09-02 16:51:00\n",
      "5                  220949\n",
      "6                   200.0\n",
      "7                      ml\n",
      "8                     NaN\n",
      "9                     NaN\n",
      "10                   84.9\n",
      "Name: 451361, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25494/25494 [01:40<00:00, 252.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2193-11-21 19:44:00\n",
      "outtime   2193-11-28 07:41:08\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               11950244\n",
      "1               28956626\n",
      "2               30794450\n",
      "3    2193-11-26 17:00:00\n",
      "4                 226559\n",
      "5                    5.0\n",
      "6                     ml\n",
      "Name: 162394, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12893/12893 [00:30<00:00, 421.84it/s]\n",
      "C:\\Users\\KyuminKim\\AppData\\Local\\Temp\\ipykernel_15528\\576908058.py:37: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n"
     ]
    }
   ],
   "source": [
    "tmp_data = []\n",
    "for data_dir in dirs[2:]:\n",
    "    drop_idx = []\n",
    "    df = pd.read_csv(data_dir)\n",
    "    try:\n",
    "        df.charttime = pd.to_datetime(df.charttime)\n",
    "        cond_ct = 1\n",
    "    except:\n",
    "        df.starttime = pd.to_datetime(df.starttime)\n",
    "        df.endtime = pd.to_datetime(df.endtime)\n",
    "        cond_ct = 0\n",
    "        \n",
    "    td_list = []\n",
    "    for stay in tqdm(df.stay_id.unique()):\n",
    "        tmp_cond = icustays.stay_id == stay\n",
    "        adm = icustays.loc[tmp_cond, ('hadm_id')].reset_index(drop=True).loc[0]\n",
    "        \n",
    "        tmp_cond = admissions.hadm_id == adm\n",
    "        at, dt = admissions.loc[tmp_cond, ('admittime', 'dischtime')].reset_index(drop=True).loc[0]\n",
    "\n",
    "        tmp_cond = df.stay_id == stay\n",
    "        part_df = df.loc[tmp_cond]\n",
    "\n",
    "        if cond_ct == 1:\n",
    "            tmp_cond = (part_df.charttime > (dt+datetime.timedelta(days=2))) | (part_df.charttime < (at-datetime.timedelta(days=2)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.charttime > (dt+datetime.timedelta(days=2))), 'charttime'] - dt)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((at - part_df.loc[(part_df.charttime < (at-datetime.timedelta(days=2))), 'charttime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "        else:\n",
    "            tmp_cond = (part_df.starttime > (dt+datetime.timedelta(days=2))) | (part_df.endtime < (at-datetime.timedelta(days=2)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.starttime > (dt+datetime.timedelta(days=2))), 'starttime'] - dt)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((at - part_df.loc[(part_df.endtime < (at-datetime.timedelta(days=2))), 'endtime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "    if len(drop_idx) == 0:\n",
    "        tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n",
    "        df = df.drop(drop_idx).reset_index(drop=True)\n",
    "        df.to_csv(data_dir[:-5]+'TEH_v4.csv', index=False)\n",
    "    else:\n",
    "        print(icustays.loc[icustays.stay_id == df.loc[drop_idx, 'stay_id'][drop_idx[0]], ('intime', 'outtime')].reset_index(drop=True).loc[0])\n",
    "        print(df.loc[drop_idx[0]].reset_index(drop=True))\n",
    "        tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n",
    "        df = df.drop(drop_idx).reset_index(drop=True)\n",
    "        df.to_csv(data_dir[:-5]+'TEH_v4.csv', index=False)\n",
    "\n",
    "pd.DataFrame(tmp_data, columns=['df', 'b4_drop', 'a_drop', 'b4_stay', 'drop_stays', 'drop_iis', 'drop_td']).to_csv('tmp_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26622/26622 [06:46<00:00, 65.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2185-04-19 22:59:00\n",
      "outtime   2185-05-07 19:05:25\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               13077594\n",
      "1               22574617\n",
      "2               30056766\n",
      "3    2185-05-11 03:01:00\n",
      "4                 220228\n",
      "5                    7.3\n",
      "6                   g/dl\n",
      "Name: 139766, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26446/26446 [02:11<00:00, 201.56it/s]\n",
      "100%|██████████| 25494/25494 [01:46<00:00, 240.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intime    2129-05-01 23:15:00\n",
      "outtime   2129-05-25 14:21:48\n",
      "Name: 0, dtype: datetime64[ns]\n",
      "0               19776632\n",
      "1               23306501\n",
      "2               31238684\n",
      "3    2129-04-01 23:00:00\n",
      "4                 226559\n",
      "5                 1000.0\n",
      "6                     ml\n",
      "Name: 255513, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12893/12893 [00:31<00:00, 414.30it/s]\n"
     ]
    }
   ],
   "source": [
    "tmp_data = []\n",
    "for data_dir in dirs[2:]:\n",
    "    drop_idx = []\n",
    "    df = pd.read_csv(data_dir)\n",
    "    try:\n",
    "        df.charttime = pd.to_datetime(df.charttime)\n",
    "        cond_ct = 1\n",
    "    except:\n",
    "        df.starttime = pd.to_datetime(df.starttime)\n",
    "        df.endtime = pd.to_datetime(df.endtime)\n",
    "        cond_ct = 0\n",
    "        \n",
    "    td_list = []\n",
    "    for stay in tqdm(df.stay_id.unique()):\n",
    "        tmp_cond = icustays.stay_id == stay\n",
    "        adm = icustays.loc[tmp_cond, ('hadm_id')].reset_index(drop=True).loc[0]\n",
    "        \n",
    "        tmp_cond = admissions.hadm_id == adm\n",
    "        at, dt = admissions.loc[tmp_cond, ('admittime', 'dischtime')].reset_index(drop=True).loc[0]\n",
    "\n",
    "        tmp_cond = df.stay_id == stay\n",
    "        part_df = df.loc[tmp_cond]\n",
    "\n",
    "        if cond_ct == 1:\n",
    "            tmp_cond = (part_df.charttime > (dt+datetime.timedelta(days=3))) | (part_df.charttime < (at-datetime.timedelta(days=3)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.charttime > (dt+datetime.timedelta(days=3))), 'charttime'] - dt)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((at - part_df.loc[(part_df.charttime < (at-datetime.timedelta(days=3))), 'charttime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "        else:\n",
    "            tmp_cond = (part_df.starttime > (dt+datetime.timedelta(days=3))) | (part_df.endtime < (at-datetime.timedelta(days=3)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.starttime > (dt+datetime.timedelta(days=3))), 'starttime'] - dt)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((at - part_df.loc[(part_df.endtime < (at-datetime.timedelta(days=3))), 'endtime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "    if len(drop_idx) == 0:\n",
    "        tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), np.nan, np.nan])\n",
    "        df = df.drop(drop_idx).reset_index(drop=True)\n",
    "        df.to_csv(data_dir[:-5]+'TEH_v5.csv', index=False)\n",
    "    else:\n",
    "        print(admissions.loc[admissions.hadm_id == df.loc[drop_idx, 'hadm_id'][drop_idx[0]], ('admittime', 'dischtime')].reset_index(drop=True).loc[0])\n",
    "        print(df.loc[drop_idx[0]].reset_index(drop=True))\n",
    "        tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.stay_id.unique()), len(df.loc[drop_idx].stay_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n",
    "        df = df.drop(drop_idx).reset_index(drop=True)\n",
    "        df.to_csv(data_dir[:-5]+'TEH_v5.csv', index=False)\n",
    "\n",
    "\n",
    "pd.DataFrame(tmp_data, columns=['df', 'b4_drop', 'a_drop', 'b4_stay', 'drop_stays', 'drop_iis', 'drop_td']).to_csv('tmp_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21912/21912 [01:48<00:00, 202.65it/s]\n"
     ]
    }
   ],
   "source": [
    "tmp_data = []\n",
    "for data_dir in [dirs[1]]:\n",
    "    drop_idx = []\n",
    "    df = pd.read_csv(data_dir)\n",
    "    df.charttime = pd.to_datetime(df.charttime)\n",
    "    cond_ct = 1\n",
    "        \n",
    "    td_list = []\n",
    "    for adm in tqdm(df.hadm_id.unique()):\n",
    "        tmp_cond = admissions.hadm_id == adm\n",
    "        at, dt = admissions.loc[tmp_cond, ('admittime', 'dischtime')].reset_index(drop=True).loc[0]\n",
    "\n",
    "        tmp_cond = df.hadm_id == adm\n",
    "        part_df = df.loc[tmp_cond]\n",
    "\n",
    "        if cond_ct == 1:\n",
    "            tmp_cond = (part_df.charttime > (dt+datetime.timedelta(days=3))) | (part_df.charttime < (at-datetime.timedelta(days=3)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.charttime > (dt+datetime.timedelta(days=3))), 'charttime'] - dt)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((at - part_df.loc[(part_df.charttime < (at-datetime.timedelta(days=3))), 'charttime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "        else:\n",
    "            tmp_cond = (part_df.starttime > (dt+datetime.timedelta(days=3))) | (part_df.endtime < (at-datetime.timedelta(days=3)))\n",
    "            drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "            td_list += ((part_df.loc[(part_df.starttime > (dt+datetime.timedelta(days=3))), 'starttime'] - dt)/datetime.timedelta(hours=1)).tolist()\n",
    "            td_list += ((at - part_df.loc[(part_df.endtime < (at-datetime.timedelta(days=3))), 'endtime'])/datetime.timedelta(hours=1)).tolist()\n",
    "\n",
    "    if len(drop_idx) == 0:\n",
    "        tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.hadm_id.unique()), len(df.loc[drop_idx].hadm_id.unique()), np.nan, np.nan])\n",
    "        df = df.drop(drop_idx).reset_index(drop=True)\n",
    "        df.to_csv(data_dir[:-5]+'TEH_v5.csv', index=False)\n",
    "    else:\n",
    "        print(admissions.loc[admissions.hadm_id == df.loc[drop_idx, 'hadm_id'][drop_idx[0]], ('admittime', 'dischtime')].reset_index(drop=True).loc[0])\n",
    "        print(df.loc[drop_idx[0]].reset_index(drop=True))\n",
    "        tmp_data.append([data_dir[-8:-4], df.shape[0], len(drop_idx), len(df.hadm_id.unique()), len(df.loc[drop_idx].hadm_id.unique()), df.loc[drop_idx].itemid.unique(), pd.Series(td_list).describe()])\n",
    "        df = df.drop(drop_idx).reset_index(drop=True)\n",
    "        df.to_csv(data_dir[:-5]+'TEH_v5.csv', index=False)\n",
    "\n",
    "pd.read_csv(dirs[0]).to_csv(dirs[0][:-5]+'TEH_v5.csv', index=False)\n",
    "pd.DataFrame(tmp_data, columns=['df', 'b4_drop', 'a_drop', 'b4_stay', 'drop_stays', 'drop_iis', 'drop_td']).to_csv('tmp_5.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 feature observation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# omr needs hadm ids\n",
    "dirs = [str('processed_data/sepsis/%s_TEH_v5.csv' %i) for i in ['omr', 'LE', 'CE', 'IE', 'OE', 'PE']]\n",
    "admissions = pd.read_csv('hosp/admissions.csv')\n",
    "admissions.admittime = pd.to_datetime(admissions.admittime)\n",
    "admissions.dischtime = pd.to_datetime(admissions.dischtime)\n",
    "\n",
    "df = pd.read_csv(dirs[0])\n",
    "df.charttime = pd.to_datetime(df.charttime)\n",
    "df['hadm_id'] = np.nan\n",
    "\n",
    "for sbj in tqdm(df.subject_id.unique()):\n",
    "    tmp_cond = admissions.subject_id == sbj\n",
    "    adms_list = admissions.loc[tmp_cond].hadm_id.tolist()\n",
    "\n",
    "    for adm in adms_list:\n",
    "        tmp_cond = admissions.hadm_id == adm\n",
    "        at, dt = admissions.loc[tmp_cond, ('admittime', 'dischtime')].reset_index(drop=True).loc[0]\n",
    "        \n",
    "        tmp_cond = (df.subject_id == sbj) & (df.charttime <= dt) & (df.charttime >= at)\n",
    "        df.loc[tmp_cond, 'hadm_id'] = int(adm)\n",
    "\n",
    "df.loc[:, ['hadm_id']+df.columns[0:-1].tolist()].to_csv(dirs[0], index=False)\n",
    "df.loc[:, ['hadm_id']+df.columns[0:-1].tolist()]\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before check which of the features is rarely observed, make sure that the GCS itemid from CE_R, urine output itemid from OE_R, and vent itemid from LE_R are editted.\n",
    "1. GCS itemid: [220739,223900,223901] -> 668540\n",
    "2. urine itemid: 227488 -> deleted\n",
    "3. vent itemid: 50828 -> deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [str('processed_data/sepsis/%s_R.csv' %i) for i in ['omr', 'LE', 'CE', 'IE', 'OE', 'PE']]\n",
    "icustays = pd.read_csv('processed_data/sepsis/icustays_wsusinf.csv')\n",
    "icustays.intime = pd.to_datetime(icustays.intime)\n",
    "icustays.outtime = pd.to_datetime(icustays.outtime)\n",
    "d_predictors = pd.read_csv('processed_data/sepsis/d_predictors_R.csv')\n",
    "tmp = icustays.loc[icustays.suspected_infection == 1].hadm_id.unique().tolist()\n",
    "df_prd_obs = pd.DataFrame([[0 if j !=0 else tmp[i] for j in range(d_predictors.shape[0]+1)] for i in range(len(tmp))], columns=['hadm_id']+d_predictors['items'].to_numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [05:45<00:00, 10.47s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>resp_rate</th>\n",
       "      <th>temperature</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>cvp</th>\n",
       "      <th>pao2</th>\n",
       "      <th>fio2</th>\n",
       "      <th>gcs</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>platelets</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>lactate</th>\n",
       "      <th>bun</th>\n",
       "      <th>arterial_ph</th>\n",
       "      <th>wbc</th>\n",
       "      <th>paco2</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>hematocrit</th>\n",
       "      <th>potassium</th>\n",
       "      <th>epinephrine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>norepinephrine</th>\n",
       "      <th>phenylephrine</th>\n",
       "      <th>vasopressin</th>\n",
       "      <th>urine output</th>\n",
       "      <th>sodium</th>\n",
       "      <th>crp</th>\n",
       "      <th>ventilator</th>\n",
       "      <th>fluid</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24597018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26184834</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23473524</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28662225</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24982426</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21920</th>\n",
       "      <td>29356037</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21921</th>\n",
       "      <td>22997012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21922</th>\n",
       "      <td>21439025</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21923</th>\n",
       "      <td>25744818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21924</th>\n",
       "      <td>23865745</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21925 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hadm_id  heart_rate  resp_rate  temperature  sbp  dbp  cvp  pao2  \\\n",
       "0      24597018           1          1            1    1    1    0     0   \n",
       "1      26184834           1          1            1    1    1    0     1   \n",
       "2      23473524           1          1            1    1    1    0     1   \n",
       "3      28662225           1          1            1    1    1    1     1   \n",
       "4      24982426           1          1            1    1    1    1     0   \n",
       "...         ...         ...        ...          ...  ...  ...  ...   ...   \n",
       "21920  29356037           1          1            1    1    1    0     0   \n",
       "21921  22997012           1          1            1    1    1    0     0   \n",
       "21922  21439025           1          1            1    1    1    0     0   \n",
       "21923  25744818           1          1            1    1    1    0     0   \n",
       "21924  23865745           1          1            1    1    1    0     1   \n",
       "\n",
       "       fio2  gcs  bilirubin  platelets  creatinine  lactate  bun  arterial_ph  \\\n",
       "0         0    1          0          1           1        0    1            0   \n",
       "1         1    1          1          1           1        1    1            1   \n",
       "2         1    1          1          1           1        1    1            1   \n",
       "3         1    1          1          1           1        1    1            1   \n",
       "4         1    1          1          1           1        1    1            1   \n",
       "...     ...  ...        ...        ...         ...      ...  ...          ...   \n",
       "21920     0    1          1          1           0        1    1            1   \n",
       "21921     0    1          0          1           1        0    1            0   \n",
       "21922     1    1          1          1           1        1    1            1   \n",
       "21923     0    1          1          1           1        1    1            1   \n",
       "21924     1    1          1          1           1        0    1            1   \n",
       "\n",
       "       wbc  paco2  hemoglobin  hematocrit  potassium  epinephrine  dopamine  \\\n",
       "0        1      0           1           1          1            0         0   \n",
       "1        1      1           1           1          1            0         1   \n",
       "2        1      1           1           1          1            0         0   \n",
       "3        1      1           1           1          1            0         1   \n",
       "4        1      0           1           1          1            0         1   \n",
       "...    ...    ...         ...         ...        ...          ...       ...   \n",
       "21920    1      0           1           1          1            0         0   \n",
       "21921    1      0           1           1          1            0         0   \n",
       "21922    1      0           1           1          1            0         0   \n",
       "21923    1      0           1           1          1            0         0   \n",
       "21924    1      1           1           1          1            0         0   \n",
       "\n",
       "       dobutamine  norepinephrine  phenylephrine  vasopressin  urine output  \\\n",
       "0               0               0              0            0             1   \n",
       "1               0               0              0            0             1   \n",
       "2               0               1              0            0             1   \n",
       "3               0               1              1            0             1   \n",
       "4               0               0              1            0             1   \n",
       "...           ...             ...            ...          ...           ...   \n",
       "21920           0               0              0            0             1   \n",
       "21921           0               0              0            0             1   \n",
       "21922           0               0              0            0             1   \n",
       "21923           0               0              0            0             1   \n",
       "21924           0               0              0            0             1   \n",
       "\n",
       "       sodium  crp  ventilator  fluid  weight  height  \n",
       "0           1    0           0      1       0       0  \n",
       "1           1    0           1      1       1       1  \n",
       "2           1    0           1      1       1       0  \n",
       "3           1    0           1      1       1       1  \n",
       "4           1    0           1      1       1       1  \n",
       "...       ...  ...         ...    ...     ...     ...  \n",
       "21920       1    0           0      1       0       0  \n",
       "21921       1    0           0      1       1       1  \n",
       "21922       1    0           0      1       0       1  \n",
       "21923       1    0           0      1       1       0  \n",
       "21924       1    0           1      1       1       0  \n",
       "\n",
       "[21925 rows x 34 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in tqdm(d_predictors['items']):\n",
    "    tmp_cond = d_predictors['items'] == item\n",
    "    df_names = d_predictors.iloc[tmp_cond[tmp_cond].index, 1:].T.dropna().index.tolist()\n",
    "    itemid_list = d_predictors.iloc[tmp_cond[tmp_cond].index, 1:].dropna(axis=1).to_numpy()[0].tolist()\n",
    "    for idx, dn in enumerate(df_names):\n",
    "        df = pd.read_csv(str('processed_data/sepsis/%s_TEH_v5.csv' %dn))\n",
    "        if dn == 'omr':\n",
    "            tmp_itemid = itemid_list[idx]\n",
    "            tmp_cond = df.result_name == tmp_itemid\n",
    "        else:\n",
    "            tmp_itemid = np.array(itemid_list[idx].split(',')).astype(int).tolist() if itemid_list[idx].__contains__(',') else [np.array(itemid_list[idx]).astype(int).tolist()]\n",
    "            tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "        \n",
    "        hadmids = df.loc[tmp_cond].hadm_id.unique().tolist()\n",
    "\n",
    "        tmp_cond = df_prd_obs.hadm_id.isin(hadmids)\n",
    "        df_prd_obs.loc[tmp_cond, item] = 1\n",
    "\n",
    "df_prd_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prd_obs.to_csv('processed_data/sepsis/analysis_results/FOA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing rate per feature\n",
    "(df_prd_obs.loc[:,df_prd_obs.columns[1:]].sum()/df_prd_obs.shape[0]).to_csv('processed_data/sepsis/analysis_results/FOA_missing_rate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LVNM case analysis\n",
    "labeling_variables = ['sbp', 'dbp', 'pao2', 'fio2', 'gcs', 'bilirubin', 'platelets', 'creatinine', 'lactate']\n",
    "tmp_cond = (df_prd_obs.loc[:, labeling_variables] == 0).sum(axis=1) == 0\n",
    "df_prd_obs.loc[tmp_cond].to_csv('processed_data/sepsis/analysis_results/FOA_LV_nonmissing.csv', index=False)\n",
    "(df_prd_obs.loc[tmp_cond ,df_prd_obs.columns[1:]].sum()/sum(tmp_cond)).to_csv('processed_data/sepsis/analysis_results/FOA_missing_rate_LVNM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13737\n",
      "10341\n",
      "9502\n"
     ]
    }
   ],
   "source": [
    "# LVNM case cohorts number\n",
    "tmp_cond = (df_prd_obs.loc[:, labeling_variables] == 0).sum(axis=1) == 0\n",
    "hadmids = df_prd_obs.loc[tmp_cond].hadm_id.tolist()\n",
    "tmp_cond = icustays.hadm_id.isin(hadmids)\n",
    "icustays['LVNM'] = 0\n",
    "icustays.loc[tmp_cond, 'LVNM'] = 1\n",
    "\n",
    "tmp_cond = icustays.LVNM == 1\n",
    "print(len(icustays.loc[tmp_cond].stay_id.unique()))\n",
    "print(len(icustays.loc[tmp_cond].hadm_id.unique()))\n",
    "print(len(icustays.loc[tmp_cond].subject_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the LVNM case cohorts recorded icustays\n",
    "icustays.to_csv('processed_data/sepsis/icustays_LVNM.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 wrap up and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [str('processed_data/sepsis/%s_TEH_v5.csv' %i) for i in ['omr', 'LE', 'CE', 'IE', 'OE', 'PE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we decided to delete CRP from predictors\n",
    "d_predictors = pd.read_csv('processed_data/sepsis/d_predictors_R.csv')\n",
    "tmp_cond = (d_predictors['items']=='crp')\n",
    "d_predictors.drop(tmp_cond[tmp_cond].index).to_csv('processed_data/sepsis/d_predictors_BFCC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hadm_id', 'subject_id', 'charttime', 'result_name', 'result_value'], dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'itemid', 'charttime', 'storetime', 'valuenum',\n",
      "       'valueuom'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'stay_id', 'charttime', 'itemid', 'valuenum',\n",
      "       'valueuom'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'itemid',\n",
      "       'amount', 'amountuom', 'rate', 'rateuom', 'patientweight'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'stay_id', 'charttime', 'itemid', 'value',\n",
      "       'valueuom'],\n",
      "      dtype='object')\n",
      "Index(['subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'itemid',\n",
      "       'value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# cohort selection\n",
    "icustays = pd.read_csv('processed_data/sepsis/icustays_LVNM.csv')\n",
    "hadmids = icustays.loc[icustays.LVNM == 1].hadm_id.unique().tolist()\n",
    "df_dict = {}\n",
    "\n",
    "for idx, df_dir in enumerate(dirs):\n",
    "    df = pd.read_csv(df_dir)\n",
    "\n",
    "    tmp_cond = df.hadm_id.isin(hadmids)\n",
    "    df = df.loc[tmp_cond].reset_index(drop=True)\n",
    "\n",
    "    df_dict[idx] = df\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10341/10341 [05:40<00:00, 30.37it/s]\n",
      "100%|██████████| 10341/10341 [05:32<00:00, 31.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# SBP, DBP, non inv and inv overlapping case identification\n",
    "df = df_dict[2]\n",
    "\n",
    "sbp_inv_ii = [220050,225309]\n",
    "sbp_ninv_ii = [220179]\n",
    "dbp_inv_ii = [220051,225310]\n",
    "dbp_ninv_ii = [220180]\n",
    "\n",
    "drop_idx = []\n",
    "# SBP\n",
    "tmp_cond = df.itemid.isin(sbp_inv_ii+sbp_ninv_ii)\n",
    "part_df = df.loc[tmp_cond]\n",
    "for adm in tqdm(df.hadm_id.unique()):\n",
    "    tmp_cond = part_df.hadm_id == adm\n",
    "    part_df_1 = part_df.loc[tmp_cond]\n",
    "\n",
    "    for ct in part_df_1.charttime.unique():\n",
    "        tmp_cond = part_df_1.charttime == ct\n",
    "        if sum(tmp_cond) >=2 :\n",
    "            if (sum(part_df_1.loc[tmp_cond].itemid == sbp_ninv_ii[0]) > 0) & (sum(part_df_1.loc[tmp_cond].itemid == sbp_inv_ii[0]) > 0):\n",
    "                tmp_cond = part_df_1.loc[tmp_cond].itemid == sbp_ninv_ii[0]\n",
    "                drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "\n",
    "# DBP\n",
    "tmp_cond = df.itemid.isin(dbp_inv_ii+dbp_ninv_ii)\n",
    "part_df = df.loc[tmp_cond]\n",
    "for adm in tqdm(df.hadm_id.unique()):\n",
    "    tmp_cond = part_df.hadm_id == adm\n",
    "    part_df_1 = part_df.loc[tmp_cond]\n",
    "\n",
    "    for ct in part_df_1.charttime.unique():\n",
    "        tmp_cond = part_df_1.charttime == ct\n",
    "        if sum(tmp_cond) >=2 :\n",
    "            if (sum(part_df_1.loc[tmp_cond].itemid == dbp_ninv_ii[0]) > 0) & (sum(part_df_1.loc[tmp_cond].itemid == dbp_inv_ii[0]) > 0):\n",
    "                tmp_cond = part_df_1.loc[tmp_cond].itemid == dbp_ninv_ii[0]\n",
    "                drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "\n",
    "# SBP, DBP, non inv and inv overlapping case deletion\n",
    "df_dict[2] = df.drop(drop_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 478.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of drop_idx: 237\n"
     ]
    }
   ],
   "source": [
    "# LE urine output OE urine output overlapping deletion\n",
    "# df_dict[1]: LE, df_dict[-2]: OE \n",
    "le = df_dict[1]\n",
    "oe = df_dict[4]\n",
    "\n",
    "le.charttime = pd.to_datetime(le.charttime)\n",
    "oe.charttime = pd.to_datetime(oe.charttime)\n",
    "\n",
    "raw_itemid = d_predictors.loc[(d_predictors['items'].str.lower().str.contains('urin'))&(~pd.isna(d_predictors.LE)), ('LE')].to_numpy()\n",
    "raw_itemid = raw_itemid[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "\n",
    "tmp_cond = le.itemid.isin(tmp_itemid)\n",
    "part_df_le = le.loc[tmp_cond]\n",
    "drop_idx = []\n",
    "for adm in tqdm(part_df_le.hadm_id.unique()):\n",
    "    tmp_cond = oe.hadm_id == adm\n",
    "    part_df_oe = oe.loc[tmp_cond]\n",
    "\n",
    "    if part_df_oe.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    tmp_cond = (part_df_le.hadm_id == adm) & (part_df_le.charttime <= max(part_df_oe.charttime)) & (part_df_le.charttime >= min(part_df_oe.charttime))\n",
    "    drop_idx += tmp_cond[tmp_cond].index.tolist()\n",
    "print(f'len of drop_idx: {len(drop_idx)}')\n",
    "df_dict[1] = le.drop(drop_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column selection and name alteration\n",
    "# omr\n",
    "df_dict[0].columns = ['hadm_id', 'subject_id', 'charttime', 'itemid', 'value']\n",
    "\n",
    "# LE\n",
    "df_dict[1] = df_dict[1].loc[:, ['subject_id', 'hadm_id', 'itemid', 'charttime', 'valuenum', 'valueuom']]\n",
    "df_dict[1].columns = ['subject_id', 'hadm_id', 'itemid', 'charttime', 'value', 'valueuom']\n",
    "\n",
    "# CE\n",
    "df_dict[2].columns = ['subject_id', 'hadm_id', 'stay_id', 'charttime', 'itemid', 'value', 'valueuom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all dataframes\n",
    "for idx, df_dir in enumerate(dirs):\n",
    "    df_dict[idx].to_csv(df_dir[:-10]+'BFCC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_predictors = pd.read_csv('processed_data/sepsis/d_predictors_BFCC.csv')\n",
    "d_predictors.loc[26, 'items'] = 'urine_output'\n",
    "d_predictors.to_csv('processed_data/sepsis/d_predictors_BFCC.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "icustays = pd.read_csv('processed_data/sepsis/icustays_LVNM.csv')\n",
    "tmp_cond = (icustays.LVNM == 1)\n",
    "icustays = icustays.loc[tmp_cond].reset_index(drop = True)\n",
    "icustays['intime'] = pd.to_datetime(icustays['intime'])\n",
    "icustays['outtime'] = pd.to_datetime(icustays['outtime'])\n",
    "hadmids = icustays.hadm_id.unique().tolist()\n",
    "\n",
    "df_names = ['omr', 'LE', 'CE', 'IE', 'OE', 'PE']\n",
    "df_dirs = [str('processed_data/sepsis/%s_BFCC.csv' %i) for i in df_names]\n",
    "df_dict = {}\n",
    "\n",
    "for idx, df_dir in enumerate(df_dirs):\n",
    "    df = pd.read_csv(df_dir)\n",
    "\n",
    "    if df_names[idx] in ['IE', 'PE']:\n",
    "        df.starttime = pd.to_datetime(df.starttime)\n",
    "        df.endtime = pd.to_datetime(df.endtime)\n",
    "    else:\n",
    "        df.charttime = pd.to_datetime(df.charttime)\n",
    "\n",
    "    df_dict[df_names[idx]] = df\n",
    "\n",
    "df_dict['icustays'] = icustays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10341/10341 [5:34:39<00:00,  1.94s/it]  \n"
     ]
    }
   ],
   "source": [
    "concat_data = {}\n",
    "d_predictors = pd.read_csv('processed_data/sepsis/d_predictors_BFCC.csv')\n",
    "empty_dict = {\n",
    "    'hospadm_id' : None,\n",
    "    'age' : {'charttime': [], 'value': []},\n",
    "    'gender' : {'value': []},\n",
    "    'race' : {'value': []},\n",
    "    'height': {'charttime': [], 'value': []},\n",
    "    'weight': {'charttime': [], 'value': []},\n",
    "    'bmi': {'charttime': [], 'value': []},\n",
    "    'heart_rate' : {'charttime': [], 'value': []},\n",
    "    'resp_rate' : {'charttime': [], 'value': []},\n",
    "    'temperature' : {'charttime': [], 'value': []},\n",
    "    'sbp' : {'charttime': [], 'value': []},\n",
    "    'dbp' : {'charttime': [], 'value': []},\n",
    "    'map' : {'charttime': [], 'value': []},\n",
    "    'cvp' : {'charttime': [], 'value': []},\n",
    "    'paco2' : {'charttime': [], 'value': []},\n",
    "    'pao2' : {'charttime': [], 'value': []},\n",
    "    'fio2' : {'charttime': [], 'value': []},\n",
    "    'gcs' : {'charttime': [], 'value': []},\n",
    "    'bilirubin' : {'charttime': [], 'value': []},\n",
    "    'platelets' : {'charttime': [], 'value': []},\n",
    "    'creatinine' : {'charttime': [], 'value': []},\n",
    "    'lactate' : {'charttime': [], 'value': []},\n",
    "    'bun' : {'charttime': [], 'value': []},\n",
    "    'arterial_ph' : {'charttime': [], 'value': []},\n",
    "    'wbc' : {'charttime': [], 'value': []},\n",
    "    'hemoglobin' : {'charttime': [], 'value': []},\n",
    "    'hematocrit' : {'charttime': [], 'value': []},\n",
    "    'potassium' : {'charttime': [], 'value': []},\n",
    "    'sodium' : {'charttime': [], 'value': []},\n",
    "    'urine_output' : {'charttime': [], 'value': []},\n",
    "    'epinephrine' : {'starttime': [], 'endtime': [], 'value': [], 'rate': []},\n",
    "    'dopamine' : {'starttime': [], 'endtime': [], 'value': [], 'rate': []},\n",
    "    'dobutamine' : {'starttime': [], 'endtime': [], 'value': [], 'rate': []},\n",
    "    'norepinephrine' : {'starttime': [], 'endtime': [], 'value': [], 'rate': []},\n",
    "    'phenylephrine' : {'starttime': [], 'endtime': [], 'value': [], 'rate': []},\n",
    "    'vasopressin' : {'starttime': [], 'endtime': [], 'value': [], 'rate': []},\n",
    "    'fluid' : {'starttime': [], 'endtime': [], 'value': [], 'rate': []},\n",
    "    'ventilator' : {'starttime': [], 'endtime': [], 'value': []}\n",
    "}\n",
    "\n",
    "# concatenation-----------------------------------------------------------------------------------------------------------------------------\n",
    "#for i in tqdm(range(len(hadmids))):\n",
    "#     concat_data[hadmids[i]] = data_concatenation(hadmid = hadmids[i], filling_dict=empty_dict, data_sources_dict=df_dict, predictor_df=d_predictors)\n",
    "# data_concatenation(hadmid = hadmids[0], filling_dict=empty_dict, data_sources_dict=df_dict, predictor_df=d_predictors)\n",
    "\n",
    "with mp.Pool(10) as pool:\n",
    "    pooled_result = pool.map(partial(data_concatenation, filling_dict=empty_dict, data_sources_dict=df_dict, predictor_df=d_predictors), tqdm(hadmids)) # 5:24:59\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10341/10341 [00:00<00:00, 1036597.14it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(pooled_result):\n",
    "    concat_data[i['hospadm_id']] = i\n",
    "\n",
    "with open('sepsis_condata_new.pkl','wb') as f:\n",
    "    pickle.dump(concat_data, f)\n",
    "\n",
    "\n",
    "id_list = list(concat_data.keys())\n",
    "with open('sepsis_condata_new_0.pkl','wb') as f:\n",
    "    pickle.dump(concat_data[id_list[0]], f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## after concat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after concat, the things that should be done is following:\n",
    "1. sepsis and shock timing analysis: which comes first? how fast does it comes compared with different time standards?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('sepsis_condata_new.pkl','rb') as f:\n",
    "    concat_data = pickle.load(f)\n",
    "\n",
    "id_list = list(concat_data.keys())\n",
    "item_list = list(concat_data[id_list[0]].keys())\n",
    "item_list = item_list[1:len(item_list)]\n",
    "\n",
    "demo_list = ['age', 'gender', 'race', 'height', 'weight', 'bmi']\n",
    "vital_list = ['heart_rate', 'resp_rate', 'temperature', 'sbp', 'dbp', 'map', 'cvp' 'paco2', 'pao2', 'fio2']\n",
    "lab_list = ['gcs', 'bilirubin', 'platelets', 'creatinine', 'lactate', 'bun', 'arterial_ph', 'wbc', 'hemoglobin', 'hematocrit','potassium', 'sodium']\n",
    "vaso_list = ['epinephrine', 'dopamine', 'dobutamine', 'norepinephrine', 'phenylephrine', 'vasopressin']\n",
    "fluid_list = ['fluid']\n",
    "urine_list = ['urine_output']\n",
    "vent_list = ['ventilator']\n",
    "SOFA_list = ['CNS_SOFA', 'CARDIO_SOFA', 'RESP_SOFA', 'COAG_SOFA', 'LIVER_SOFA', 'RENAL_SOFA']\n",
    "label_list = ['SEPSIS', 'SHOCK']\n",
    "\n",
    "item_dict = {\n",
    "    'ct': demo_list[3:]+vital_list+lab_list+urine_list,\n",
    "    'stet': fluid_list+vaso_list+vent_list,\n",
    "    'demo': demo_list[3:],\n",
    "    'vital': vital_list,\n",
    "    'lab': lab_list,\n",
    "    'urine': urine_list, \n",
    "    'vaso': vaso_list,\n",
    "    'fluid': fluid_list,\n",
    "    'vent': vent_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10341/10341 [04:44<00:00, 36.40it/s]\n"
     ]
    }
   ],
   "source": [
    "sepshock_adm = pd.DataFrame(columns=['hadm_id', 'sepsis', 'shock', '0tosep', '0tosho', 'septhensho', 'shothensep', 'td_sepsho'])\n",
    "sepshock_adm['hadm_id'] = id_list\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for i in tqdm(range(len(id_list))):\n",
    "    tmp_adm = id_list[i]\n",
    "    tmp_adm_data = concat_data[tmp_adm]\n",
    "\n",
    "    timepoints_list = []\n",
    "    for j in range(len(item_list[3:])):\n",
    "        tmp_item = item_list[3:][j]\n",
    "        tmp_item_data = tmp_adm_data[tmp_item]\n",
    "        try :\n",
    "            timepoints_list = timepoints_list + tmp_item_data['charttime']\n",
    "        except:\n",
    "            timepoints_list = timepoints_list + tmp_item_data['starttime']\n",
    "            timepoints_list = timepoints_list + tmp_item_data['endtime']\n",
    "    timepoints_list = pd.to_datetime(timepoints_list)\n",
    "    timepoints_list = timepoints_list.sort_values()\n",
    "    tmp_0t = timepoints_list[0]\n",
    "\n",
    "\n",
    "    # 1. sepsis 0tosep \n",
    "    tmp_item_data = tmp_adm_data['SEPSIS']\n",
    "    tmp_cond = sepshock_adm.hadm_id == tmp_adm\n",
    "    sepshock_adm.loc[tmp_cond, 'sepsis'] = int((sum(tmp_item_data['value']) > 0))\n",
    "\n",
    "    if sepshock_adm.loc[tmp_cond, 'sepsis'].tolist()[0] == 1:\n",
    "        tmp_idx = tmp_item_data['value'].index(1)\n",
    "        tmp_st = pd.to_datetime(tmp_item_data['starttime'])[tmp_idx]\n",
    "        sepshock_adm.loc[tmp_cond, '0tosep'] = (tmp_st-tmp_0t)/datetime.timedelta(hours=1)\n",
    "    \n",
    "\n",
    "    # 2. shock 0tosho\n",
    "    tmp_item_data = tmp_adm_data['SHOCK']\n",
    "    tmp_cond = sepshock_adm.hadm_id == tmp_adm\n",
    "    sepshock_adm.loc[tmp_cond, 'shock'] = int((sum(tmp_item_data['value']) > 0))\n",
    "    \n",
    "    if sepshock_adm.loc[tmp_cond, 'shock'].tolist()[0] == 1:\n",
    "        tmp_idx = tmp_item_data['value'].index(1)\n",
    "        tmp_st = pd.to_datetime(tmp_item_data['starttime'])[tmp_idx]\n",
    "        sepshock_adm.loc[tmp_cond, '0tosho'] = (tmp_st-tmp_0t)/datetime.timedelta(hours=1)\n",
    "\n",
    "\n",
    "    # 3. septhensho shothensep td_sepsho\n",
    "    if ((sepshock_adm.loc[tmp_cond, 'sepsis'][i] == 1) & (sepshock_adm.loc[tmp_cond, 'shock'][i] == 1)):\n",
    "        sepshock_adm.loc[tmp_cond, 'septhensho'] = int((sepshock_adm.loc[tmp_cond, '0tosho'] > sepshock_adm.loc[tmp_cond, '0tosep']))\n",
    "        sepshock_adm.loc[tmp_cond, 'shothensep'] = int((sepshock_adm.loc[tmp_cond, '0tosho'] <= sepshock_adm.loc[tmp_cond, '0tosep']))\n",
    "        sepshock_adm.loc[tmp_cond, 'td_sepsho'] = abs(sepshock_adm.loc[tmp_cond, '0tosho'] - sepshock_adm.loc[tmp_cond, '0tosep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5236.000000\n",
       "mean      112.551308\n",
       "std       234.841894\n",
       "min         0.016667\n",
       "1%          0.116667\n",
       "5%          0.566667\n",
       "10%         1.258333\n",
       "25%         4.029167\n",
       "50%        22.291667\n",
       "75%       133.195833\n",
       "90%       319.666806\n",
       "95%       490.070833\n",
       "99%       992.528333\n",
       "max      4926.516667\n",
       "Name: 0tosho, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepshock_adm.loc[sepshock_adm.septhensho == 1 ,'0tosho'].astype('float').describe([i*0.01 for i in [1, 5, 10, 25, 50, 75, 90, 95, 99]])#.to_csv('processed_data/sepsis/analysis_results/sepshock_sish_0tosho_admver.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepsis num, ratio: 10285, 0.9945846629919737\n",
      "shock num, ratio: 5412, 0.5233536408471134\n",
      "septhensho num, ratio(/total): 5236, 0.9676584734799483\n",
      "shothensep num, ratio(/total): 175, 0.03234152652005175\n",
      "septhensho ratio(/total): 0.5063340102504593\n",
      "shothensep ratio(/total): 0.016922928150082197\n",
      "\n",
      "==========0 to sep========== \n",
      "count    10285.000000\n",
      "mean        10.371926\n",
      "std         50.308824\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max       1862.216667\n",
      "Name: 0tosep, dtype: float64\n",
      "\n",
      "\n",
      "==========0 to shock========== \n",
      "count    5412.000000\n",
      "mean      111.039890\n",
      "std       232.135914\n",
      "min         0.000000\n",
      "25%         3.933333\n",
      "50%        22.041667\n",
      "75%       129.608333\n",
      "max      4926.516667\n",
      "Name: 0tosho, dtype: float64\n",
      "\n",
      "\n",
      "==========td sepsho========== \n",
      "count    5411.000000\n",
      "mean      103.380732\n",
      "std       228.251217\n",
      "min         0.000000\n",
      "25%         3.200000\n",
      "50%        17.333333\n",
      "75%       113.766667\n",
      "max      4926.516667\n",
      "Name: td_sepsho, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'sepsis num, ratio: {sum(sepshock_adm.sepsis)}, {sum(sepshock_adm.sepsis)/sepshock_adm.shape[0]}')\n",
    "print(f'shock num, ratio: {sum(sepshock_adm.shock)}, {sum(sepshock_adm.shock)/sepshock_adm.shape[0]}')\n",
    "print(f'septhensho num, ratio(/total): {np.nansum(sepshock_adm.septhensho)}, {np.nansum(sepshock_adm.septhensho)/sum((sepshock_adm.sepsis==1)&(sepshock_adm.shock==1))}')\n",
    "print(f'shothensep num, ratio(/total): {np.nansum(sepshock_adm.shothensep)}, {np.nansum(sepshock_adm.shothensep)/sum((sepshock_adm.sepsis==1)&(sepshock_adm.shock==1))}')\n",
    "print(f'septhensho ratio(/total): {np.nansum(sepshock_adm.septhensho)/sepshock_adm.shape[0]}')\n",
    "print(f'shothensep ratio(/total): {np.nansum(sepshock_adm.shothensep)/sepshock_adm.shape[0]}')\n",
    "print(f\"\\n==========0 to sep========== \\n{sepshock_adm['0tosep'].astype('float').describe()}\\n\")\n",
    "print(f\"\\n==========0 to shock========== \\n{sepshock_adm['0tosho'].astype('float').describe()}\\n\")\n",
    "print(f\"\\n==========td sepsho========== \\n{sepshock_adm['td_sepsho'].astype('float').describe()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "icustays = pd.read_csv('processed_data/sepsis/icustays_LVNM.csv')\n",
    "tmp_cond = icustays.LVNM == 1\n",
    "stayids = icustays.loc[tmp_cond].stay_id.unique().tolist()\n",
    "icustays.intime = pd.to_datetime(icustays.intime)\n",
    "icustays.outtime = pd.to_datetime(icustays.outtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13737/13737 [01:39<00:00, 138.55it/s]\n"
     ]
    }
   ],
   "source": [
    "sepshock = pd.DataFrame(columns=['stay_id', 'sepsis', 'shock', '0tosep', '0tosho', 'septhensho', 'shothensep', 'td_sepsho', 'td_stit'])\n",
    "sepshock['stay_id'] = stayids\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "for i in tqdm(range(len(stayids))):\n",
    "    tmp_stay = stayids[i]\n",
    "    tmp_cond = icustays.stay_id == tmp_stay\n",
    "    tmp_adm = icustays.loc[tmp_cond].hadm_id.tolist()[0]\n",
    "    it, ot = icustays.loc[tmp_cond, ('intime', 'outtime')].reset_index(drop=True).loc[0]\n",
    "    tmp_adm_data = concat_data[tmp_adm]\n",
    "\n",
    "    # 1. sepsis 0tosep \n",
    "    tmp_item_data = pd.DataFrame(tmp_adm_data['SEPSIS'])\n",
    "    tmp_cond = (tmp_item_data.endtime >= it) & (tmp_item_data.starttime <= ot)\n",
    "    tmp_stay_item_df = tmp_item_data.loc[tmp_cond].reset_index(drop=True)\n",
    "    tmp_0t = tmp_stay_item_df.starttime[0]\n",
    "\n",
    "    tmp_cond = sepshock.stay_id == tmp_stay\n",
    "    sepshock.loc[tmp_cond, 'sepsis'] = int((sum(tmp_stay_item_df['value']) > 0)) # sepsis\n",
    "    sepshock.loc[tmp_cond, 'td_stit'] = (it-tmp_0t)/datetime.timedelta(hours=1)\n",
    "    \n",
    "    if sepshock.loc[tmp_cond, 'sepsis'].tolist()[0] == 1:\n",
    "        tmp_idx = tmp_stay_item_df['value'].tolist().index(1)\n",
    "        tmp_st = pd.to_datetime(tmp_stay_item_df['starttime'])[tmp_idx]\n",
    "        sepshock.loc[tmp_cond, '0tosep'] = (tmp_st-tmp_0t)/datetime.timedelta(hours=1)\n",
    "\n",
    "\n",
    "    # 2. shock 0tosho\n",
    "    tmp_item_data = pd.DataFrame(tmp_adm_data['SHOCK'])\n",
    "    tmp_cond = (tmp_item_data.endtime >= it) & (tmp_item_data.starttime <= ot)\n",
    "    tmp_stay_item_df = tmp_item_data.loc[tmp_cond].reset_index(drop=True)\n",
    "\n",
    "    tmp_cond = sepshock.stay_id == tmp_stay\n",
    "    sepshock.loc[tmp_cond, 'shock'] = int((sum(tmp_stay_item_df['value']) > 0)) # sepsis\n",
    "    \n",
    "    if sepshock.loc[tmp_cond, 'shock'].tolist()[0] == 1:\n",
    "        tmp_idx = tmp_stay_item_df['value'].tolist().index(1)\n",
    "        tmp_st = tmp_stay_item_df['starttime'][tmp_idx]\n",
    "        sepshock.loc[tmp_cond, '0tosho'] = (tmp_st-tmp_0t)/datetime.timedelta(hours=1)\n",
    "\n",
    "\n",
    "    # 3. septhensho shothensep td_sepsho\n",
    "    if ((sepshock.loc[tmp_cond, 'sepsis'][i] == 1) & (sepshock.loc[tmp_cond, 'shock'][i] == 1)):\n",
    "        sepshock.loc[tmp_cond, 'septhensho'] = int((sepshock.loc[tmp_cond, '0tosho'] > sepshock.loc[tmp_cond, '0tosep']))\n",
    "        sepshock.loc[tmp_cond, 'shothensep'] = int((sepshock.loc[tmp_cond, '0tosho'] <= sepshock.loc[tmp_cond, '0tosep']))\n",
    "        sepshock.loc[tmp_cond, 'td_sepsho'] = abs(sepshock.loc[tmp_cond, '0tosho'] - sepshock.loc[tmp_cond, '0tosep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepsis_stays = sepshock.stay_id[sepshock.sepsis == 1].tolist()\n",
    "shock_stays = sepshock.stay_id[sepshock.shock == 1].tolist()\n",
    "septhensho_stays = sepshock.stay_id[sepshock.septhensho == 1].tolist()\n",
    "shothensep_stays = sepshock.stay_id[sepshock.shothensep == 1].tolist()\n",
    "\n",
    "icustays.loc[icustays.stay_id.isin(sepsis_stays), 'sepsis'] = 1\n",
    "icustays.loc[icustays.stay_id.isin(shock_stays), 'shock'] = 1\n",
    "icustays.loc[icustays.stay_id.isin(septhensho_stays), 'septhensho'] = 1\n",
    "icustays.loc[icustays.stay_id.isin(shothensep_stays), 'shothensep'] = 1\n",
    "icustays.loc[((icustays.sepsis == 1) & (icustays.shothensep != 1)), 'cohort_stays'] = 1\n",
    "\n",
    "icustays.to_csv('processed_data/sepsis/icustays_sepshock.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepsis num, ratio: 13285, 0.9670961636456286\n",
      "shock num, ratio: 5871, 0.42738589211618255\n",
      "septhensho num, ratio(/total): 5400, 0.9204022498721663\n",
      "shothensep num, ratio(/total): 467, 0.07959775012783364\n",
      "septhensho ratio(/total): 0.3930989298973575\n",
      "shothensep ratio(/total): 0.03399577782630851\n",
      "\n",
      "==========0 to sep========== \n",
      "count    13285.000000\n",
      "mean         2.401771\n",
      "std         10.308149\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max        245.000000\n",
      "Name: 0tosep, dtype: float64\n",
      "\n",
      "\n",
      "==========0 to shock========== \n",
      "count    5871.000000\n",
      "mean       28.612400\n",
      "std        75.720241\n",
      "min         0.000000\n",
      "25%         1.066667\n",
      "50%         4.383333\n",
      "75%        19.100000\n",
      "max      1530.183333\n",
      "Name: 0tosho, dtype: float64\n",
      "\n",
      "\n",
      "==========td sepsho========== \n",
      "count    5867.000000\n",
      "mean       27.417059\n",
      "std        74.722382\n",
      "min         0.000000\n",
      "25%         0.866667\n",
      "50%         3.883333\n",
      "75%        16.958333\n",
      "max      1530.183333\n",
      "Name: td_sepsho, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'sepsis num, ratio: {sum(sepshock.sepsis)}, {sum(sepshock.sepsis)/sepshock.shape[0]}')\n",
    "print(f'shock num, ratio: {sum(sepshock.shock)}, {sum(sepshock.shock)/sepshock.shape[0]}')\n",
    "print(f'septhensho num, ratio(/total): {np.nansum(sepshock.septhensho)}, {np.nansum(sepshock.septhensho)/sum((sepshock.sepsis==1)&(sepshock.shock==1))}')\n",
    "print(f'shothensep num, ratio(/total): {np.nansum(sepshock.shothensep)}, {np.nansum(sepshock.shothensep)/sum((sepshock.sepsis==1)&(sepshock.shock==1))}')\n",
    "print(f'septhensho ratio(/total): {np.nansum(sepshock.septhensho)/sepshock.shape[0]}')\n",
    "print(f'shothensep ratio(/total): {np.nansum(sepshock.shothensep)/sepshock.shape[0]}')\n",
    "print(f\"\\n==========0 to sep========== \\n{sepshock['0tosep'].astype('float').describe()}\\n\")\n",
    "print(f\"\\n==========0 to shock========== \\n{sepshock['0tosho'].astype('float').describe()}\\n\")\n",
    "print(f\"\\n==========td sepsho========== \\n{sepshock['td_sepsho'].astype('float').describe()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5400.000000\n",
       "mean       30.603762\n",
       "std        78.460404\n",
       "min         0.016667\n",
       "1%          0.050000\n",
       "5%          0.183333\n",
       "10%         0.400000\n",
       "25%         1.400000\n",
       "50%         4.900000\n",
       "75%        21.141667\n",
       "90%        80.613333\n",
       "95%       150.537500\n",
       "99%       380.435667\n",
       "max      1530.183333\n",
       "Name: 0tosho, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepshock.loc[sepshock.septhensho == 1 ,'0tosho'].astype('float').describe([i*0.01 for i in [1, 5, 10, 25, 50, 75, 90, 95, 99]])#.to_csv('processed_data/sepsis/analysis_results/sepshock_sish_0tosho_stayver.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5400.000000\n",
       "mean        0.594082\n",
       "std         2.050999\n",
       "min        -3.451944\n",
       "1%         -0.683622\n",
       "5%          0.000278\n",
       "10%         0.001944\n",
       "25%         0.006944\n",
       "50%         0.014722\n",
       "75%         0.400000\n",
       "90%         1.465917\n",
       "95%         2.549208\n",
       "99%        10.234167\n",
       "max        47.662778\n",
       "Name: td_stit, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepshock.loc[sepshock.septhensho == 1 ,'td_stit'].astype('float').describe([i*0.01 for i in [1, 5, 10, 25, 50, 75, 90, 95, 99]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    13737.000000\n",
       "mean         0.744949\n",
       "std          2.632894\n",
       "min         -5.339722\n",
       "1%          -1.002478\n",
       "5%           0.000000\n",
       "10%          0.001944\n",
       "25%          0.007222\n",
       "50%          0.016667\n",
       "75%          0.500000\n",
       "90%          1.683333\n",
       "95%          3.468167\n",
       "99%         12.780289\n",
       "max         91.792222\n",
       "Name: td_stit, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sepshock.loc[: ,'td_stit'].astype('float').describe([i*0.01 for i in [1, 5, 10, 25, 50, 75, 90, 95, 99]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9934141abaf46ce0fca32690cf02266115d4467700627d173c843f0169c9d143"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
