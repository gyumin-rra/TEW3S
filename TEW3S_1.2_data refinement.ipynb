{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinement Procedure\n",
    "for each dataset, do the following refinement process. it doesnt have to be executed in listed order.\n",
    "1. Process miscellaneous things.\n",
    "2. unit conversion\n",
    "3. outlier deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from warnings import simplefilter\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "simplefilter(action=\"ignore\", category=pd.errors.DtypeWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dirs = [str('processed_data/sepsis/%s_SCR.csv' %i) for i in ['omr', 'LE', 'CE', 'IE', 'OE', 'PE']]\n",
    "\n",
    "def inch_to_cm(x):\n",
    "    x = np.array(x).astype('float')\n",
    "\n",
    "    return x*2.54\n",
    "\n",
    "def lbs_to_kg(x):\n",
    "    x = np.array(x).astype('float')\n",
    "\n",
    "    return x/2.205\n",
    "\n",
    "def F_to_C(x):\n",
    "    x = np.array(x).astype('float')\n",
    "\n",
    "    return (x-32)*5/9\n",
    "\n",
    "def mcg_to_mg(x):\n",
    "    x = np.array(x).astype('float')\n",
    "\n",
    "    return x/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. omr processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dirs[0])\n",
    "# date to time\n",
    "# for avoding information leakage, time of dates in omr data is assumed as the last time(23:59:59) of the date.\n",
    "df.chartdate = pd.to_datetime(df.chartdate + ' 23:59:59')\n",
    "df.columns = [i if idx!=1 else 'charttime' for idx, i in enumerate(df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12639/12639 [02:14<00:00, 93.99it/s] \n"
     ]
    }
   ],
   "source": [
    "# we will use only the information of the selected cohorts' admission\n",
    "admissions = pd.read_csv('hosp/admissions.csv')\n",
    "admissions.admittime = pd.to_datetime(admissions.admittime) \n",
    "admissions.dischtime = pd.to_datetime(admissions.dischtime) \n",
    "icustays = pd.read_csv('processed_data/sepsis/icustays_wsusinf.csv')\n",
    "subjectid = df.subject_id.unique().tolist()\n",
    "\n",
    "include_idx = []\n",
    "for sbj_id in tqdm(subjectid):\n",
    "    tmp_cond = (icustays.suspected_infection == 1) & (icustays.subject_id == sbj_id)\n",
    "    adm_id = icustays.loc[tmp_cond].hadm_id.tolist()\n",
    "    \n",
    "    ATDT = admissions.loc[admissions.hadm_id.isin(adm_id), ('admittime', 'dischtime')].reset_index(drop=True)\n",
    "    \n",
    "    for i in range(ATDT.shape[0]):\n",
    "        tmp_cond = (df.subject_id == sbj_id) & (df.charttime >= ATDT.loc[i].tolist()[0]) & (df.charttime <= ATDT.loc[i].tolist()[1])\n",
    "        include_idx += tmp_cond.index[tmp_cond].tolist()\n",
    "df = df.iloc[include_idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: result_name, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# missing value handling\n",
    "print(df.loc[pd.isna(df.result_value)].result_name.value_counts())\n",
    "df = df.drop(pd.isna(df.result_value).index[pd.isna(df.result_value)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3797/3797 [00:03<00:00, 1248.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# leave only the latest item,  if two same items exists at the same time\n",
    "drop_idx = []\n",
    "for sbj in tqdm(df.subject_id.unique()):\n",
    "    tmp_cond = df.subject_id == sbj\n",
    "    part_df = df.loc[tmp_cond]\n",
    "\n",
    "    for ct in part_df.charttime.unique():\n",
    "        tmp_cond = (part_df.charttime == ct)\n",
    "        part_df_2 = part_df.loc[tmp_cond]\n",
    "\n",
    "        for rn in part_df_2.result_name.unique():\n",
    "            tmp_cond = (part_df_2.result_name == rn)\n",
    "            if sum(tmp_cond) > 1:\n",
    "                drop_idx += [i for i in tmp_cond.index[tmp_cond] if i != tmp_cond.index[tmp_cond][-1]]\n",
    "\n",
    "df = df.drop(drop_idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1146/1146 [00:00<00:00, 8293.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# blood pressure processing\n",
    "# the blood pressure value is wriiten as sbp/dbp.\n",
    "# validate the sbp > dbp and split them to two rows.\n",
    "tmp_data = []\n",
    "tmp_cond = (df.result_name.str.contains('Blood'))\n",
    "\n",
    "for idx in tqdm(tmp_cond[tmp_cond].index):\n",
    "    sbj, ct = df.iloc[idx, 0:2]\n",
    "    sbp, dbp = df.iloc[idx, -1].split('/')\n",
    "    sbp, dbp = int(sbp), int(dbp) \n",
    "\n",
    "    if sbp > dbp:\n",
    "        tmp_data.append([sbj, ct, 'SBP', sbp])\n",
    "        tmp_data.append([sbj, ct, 'DBP', dbp])\n",
    "\n",
    "tmp_data = pd.DataFrame(tmp_data, columns=[i for i in df.columns if i != 'seq_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace blood pressure data to new one\n",
    "# and also drop eGFR, BMI\n",
    "tmp_cond = (df.result_name.str.contains('Blood|eGFR|BMI'))\n",
    "df = df.drop(tmp_cond[tmp_cond].index)\n",
    "\n",
    "df = pd.concat([df.loc[:, [i for i in df.columns if i != 'seq_num']], tmp_data], axis=0).sort_values(['subject_id', 'charttime']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [subject_id, charttime, result_name, result_value]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# check if df has result value that can not be type conversed to float.\n",
    "drop_idx = []\n",
    "for i in df.index:\n",
    "    try:\n",
    "        tmp = float(df.iloc[i, -1])\n",
    "    except:\n",
    "        drop_idx.append(i)\n",
    "print(df.iloc[drop_idx])\n",
    "df = df.drop(drop_idx).reset_index(drop=True) ##### really important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we do unit conversion for OMR\n",
    "tmp_cond = (df.result_name.str.contains('Inches'))\n",
    "df.loc[tmp_cond, 'result_value'] = inch_to_cm(df.loc[tmp_cond, 'result_value'])\n",
    "df.loc[tmp_cond, 'result_name'] = 'Height'\n",
    "\n",
    "tmp_cond = (df.result_name.str.contains('Lbs'))\n",
    "df.loc[tmp_cond, 'result_value'] = lbs_to_kg(df.loc[tmp_cond, 'result_value'])\n",
    "df.loc[tmp_cond, 'result_name'] = 'Weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weight    3944\n",
       "Height    2098\n",
       "SBP       1146\n",
       "DBP       1146\n",
       "Name: result_name, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.result_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>0.1%</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>99.9%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>1146.0</td>\n",
       "      <td>69.109948</td>\n",
       "      <td>13.885878</td>\n",
       "      <td>28.0</td>\n",
       "      <td>29.14500</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>69.00000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>102.550000</td>\n",
       "      <td>113.855000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>2098.0</td>\n",
       "      <td>167.287294</td>\n",
       "      <td>16.222356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49276</td>\n",
       "      <td>137.083800</td>\n",
       "      <td>152.400000</td>\n",
       "      <td>167.64000</td>\n",
       "      <td>184.150000</td>\n",
       "      <td>190.500000</td>\n",
       "      <td>198.120000</td>\n",
       "      <td>449.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBP</th>\n",
       "      <td>1146.0</td>\n",
       "      <td>120.684119</td>\n",
       "      <td>22.614476</td>\n",
       "      <td>52.0</td>\n",
       "      <td>60.87000</td>\n",
       "      <td>73.450000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>119.00000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>221.275000</td>\n",
       "      <td>226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>3944.0</td>\n",
       "      <td>80.020535</td>\n",
       "      <td>25.435669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>36.527438</td>\n",
       "      <td>48.075283</td>\n",
       "      <td>76.78458</td>\n",
       "      <td>124.235147</td>\n",
       "      <td>154.416009</td>\n",
       "      <td>225.543946</td>\n",
       "      <td>550.195011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count        mean        std   min      0.1%          1%  \\\n",
       "result_name                                                              \n",
       "DBP          1146.0   69.109948  13.885878  28.0  29.14500   40.000000   \n",
       "Height       2098.0  167.287294  16.222356   0.0   0.49276  137.083800   \n",
       "SBP          1146.0  120.684119  22.614476  52.0  60.87000   73.450000   \n",
       "Weight       3944.0   80.020535  25.435669   0.0   0.00000   36.527438   \n",
       "\n",
       "                     5%        50%         95%         99%       99.9%  \\\n",
       "result_name                                                              \n",
       "DBP           47.000000   69.00000   92.000000  102.550000  113.855000   \n",
       "Height       152.400000  167.64000  184.150000  190.500000  198.120000   \n",
       "SBP           87.000000  119.00000  159.000000  184.000000  221.275000   \n",
       "Weight        48.075283   76.78458  124.235147  154.416009  225.543946   \n",
       "\n",
       "                    max  \n",
       "result_name              \n",
       "DBP          120.000000  \n",
       "Height       449.580000  \n",
       "SBP          226.000000  \n",
       "Weight       550.195011  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value distribution describe\n",
    "df.result_value = df.result_value.astype('float')\n",
    "df.groupby('result_name').result_value.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1002.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>result_name</th>\n",
       "      <th>result_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001884</td>\n",
       "      <td>2131-01-07 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>68.689342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10003400</td>\n",
       "      <td>2137-02-24 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>83.764172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003400</td>\n",
       "      <td>2137-08-05 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>97.505669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10007818</td>\n",
       "      <td>2146-06-10 23:59:59</td>\n",
       "      <td>Height</td>\n",
       "      <td>185.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10007818</td>\n",
       "      <td>2146-06-10 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>89.183673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8329</th>\n",
       "      <td>19996783</td>\n",
       "      <td>2188-05-10 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>60.770975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8330</th>\n",
       "      <td>19997367</td>\n",
       "      <td>2127-04-02 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>55.487528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8331</th>\n",
       "      <td>19997473</td>\n",
       "      <td>2173-09-11 23:59:59</td>\n",
       "      <td>Height</td>\n",
       "      <td>158.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>19997473</td>\n",
       "      <td>2173-09-11 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>64.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8333</th>\n",
       "      <td>19997886</td>\n",
       "      <td>2186-11-12 23:59:59</td>\n",
       "      <td>Weight</td>\n",
       "      <td>67.886621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8330 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject_id           charttime result_name  result_value\n",
       "0       10001884 2131-01-07 23:59:59      Weight     68.689342\n",
       "1       10003400 2137-02-24 23:59:59      Weight     83.764172\n",
       "2       10003400 2137-08-05 23:59:59      Weight     97.505669\n",
       "3       10007818 2146-06-10 23:59:59      Height    185.420000\n",
       "4       10007818 2146-06-10 23:59:59      Weight     89.183673\n",
       "...          ...                 ...         ...           ...\n",
       "8329    19996783 2188-05-10 23:59:59      Weight     60.770975\n",
       "8330    19997367 2127-04-02 23:59:59      Weight     55.487528\n",
       "8331    19997473 2173-09-11 23:59:59      Height    158.750000\n",
       "8332    19997473 2173-09-11 23:59:59      Weight     64.489796\n",
       "8333    19997886 2186-11-12 23:59:59      Weight     67.886621\n",
       "\n",
       "[8330 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight and height, will be concat into one df and then the outlier criteria will determined.\n",
    "# for DBP, 10<=dbp<=175 were used \n",
    "# for SBP, 0<SBP<=300 were used\n",
    "drop_idx = []\n",
    "drop_bp_idx = []\n",
    "# Height                                    \n",
    "tmp_cond = ((df.result_name == 'Height') & ((df.result_value < 0) | (df.result_value > 240)))\n",
    "drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "drop_bp_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "# Weight\n",
    "tmp_cond = ((df.result_name == 'Weight') & ((df.result_value < 0) | (df.result_value > 250)))\n",
    "drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "drop_bp_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "# SBP\n",
    "tmp_cond = ((df.result_name == 'SBP') & ((df.result_value <= 0) | (df.result_value > 300)))\n",
    "drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "drop_bp_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "# SBP\n",
    "tmp_cond = ((df.result_name == 'SBP') & ((df.result_value <= 0) | (df.result_value > 300)))\n",
    "drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "drop_bp_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "# DBP\n",
    "tmp_cond = ((df.result_name == 'DBP') & ((df.result_value < 10) | (df.result_value > 175)))\n",
    "drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "drop_bp_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "# corresponding SBP, DBP deletion\n",
    "for idx in tqdm(drop_bp_idx):\n",
    "    sbj, ct = df.iloc[idx, 0:2]\n",
    "\n",
    "    tmp_cond = (df.subject_id == sbj) & (df.charttime == ct) & (df.result_name.isin(['SBP', 'DBP']))\n",
    "    drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "df.drop(drop_idx)# 4 rows were deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete outliers and save the refined dataframe\n",
    "df.drop(drop_idx).to_csv('processed_data/sepsis/omr_R.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. labevents processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dirs[1])\n",
    "df.charttime = pd.to_datetime(df.charttime) # for time should be able to calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the d_predictor, choose the item ids for labevents\n",
    "d_predictor = pd.read_csv('processed_data/sepsis/d_predictors.csv')\n",
    "tmp = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()]\n",
    "itemids_LE = []\n",
    "for i in tmp: \n",
    "    itemids_LE += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data to have only predictor relevant rows and relevent columns\n",
    "tmp_cond = df.itemid.isin(itemids_LE)\n",
    "df = df.loc[tmp_cond, ('subject_id', 'hadm_id', 'itemid', 'charttime', 'storetime', 'valuenum', 'valueuom')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000535/4000535 [01:02<00:00, 64457.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [subject_id, hadm_id, itemid, charttime, storetime, valuenum, valueuom]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# check if df has result value that can not be type conversed to float.\n",
    "# float(df.iloc[:, -2])\n",
    "drop_idx = []\n",
    "for i in tqdm(df.index):\n",
    "    try:\n",
    "        tmp = float(df.iloc[i, -2])\n",
    "    except:\n",
    "        drop_idx.append(i)\n",
    "print(df.iloc[drop_idx])\n",
    "df = df.drop(drop_idx).reset_index(drop=True) ##### really important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50828    24792\n",
      "51265     1663\n",
      "50885     1340\n",
      "51301     1258\n",
      "51221      965\n",
      "51222      787\n",
      "50889      394\n",
      "50971      359\n",
      "51006      350\n",
      "50820      122\n",
      "50983       85\n",
      "50813       80\n",
      "51108        2\n",
      "50825        1\n",
      "Name: itemid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# missing value handling\n",
    "print(df.loc[pd.isna(df.valuenum)].itemid.value_counts())\n",
    "df = df.drop(pd.isna(df.valuenum).index[pd.isna(df.valuenum)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Temperature', 'Bilirubin', 'Platelets', 'Creatinine', 'Lactate',\n",
       "       'BUN', 'Arterial pH', 'WBC', 'Hemoglobin', 'Hematocrit',\n",
       "       'Potassium', 'Urine output', 'Sodium', 'C Reactive Protein',\n",
       "       'Ventilator'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit conversion\n",
    "# check which item may need unit conversion \n",
    "d_predictor['items'][~pd.isna(d_predictor.LE)].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: valueuom, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    71984.000000\n",
       "mean        37.030992\n",
       "std          1.029730\n",
       "min          0.000000\n",
       "0.1%        32.000000\n",
       "1%          33.900000\n",
       "5%          35.600000\n",
       "50%         37.000000\n",
       "95%         38.600000\n",
       "99%         39.400000\n",
       "99.9%       40.300000\n",
       "max         57.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temperature\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][0]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# because it is not written in dataset, we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])\n",
    "# we can think that the temperatuer unit is Celcius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/dL    157420\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    157420.000000\n",
       "mean          4.165599\n",
       "std           7.750764\n",
       "min           0.000000\n",
       "0.1%          0.100000\n",
       "1%            0.200000\n",
       "5%            0.200000\n",
       "50%           1.100000\n",
       "95%          21.300000\n",
       "99%          38.800000\n",
       "99.9%        56.600000\n",
       "max          87.200000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bilirubin\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][1]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K/uL    439772\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    439772.000000\n",
       "mean        218.966494\n",
       "std         158.907163\n",
       "min           5.000000\n",
       "0.1%          6.000000\n",
       "1%           12.000000\n",
       "5%           30.000000\n",
       "50%         190.000000\n",
       "95%         516.000000\n",
       "99%         739.000000\n",
       "99.9%      1126.229000\n",
       "max        2009.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# platelets\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][2]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/dL    55\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    55.000000\n",
       "mean      1.794545\n",
       "std       1.348857\n",
       "min       0.100000\n",
       "0.1%      0.105400\n",
       "1%        0.154000\n",
       "5%        0.570000\n",
       "50%       1.300000\n",
       "95%       3.560000\n",
       "99%       6.312000\n",
       "99.9%     7.381200\n",
       "max       7.500000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creatinine\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][3]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmol/L    177872\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.778720e+05\n",
       "mean     9.794278e+00\n",
       "std      3.025737e+03\n",
       "min      0.000000e+00\n",
       "0.1%     4.000000e-01\n",
       "1%       6.000000e-01\n",
       "5%       8.000000e-01\n",
       "50%      1.800000e+00\n",
       "95%      7.600000e+00\n",
       "99%      1.390000e+01\n",
       "99.9%    2.100000e+01\n",
       "max      1.276103e+06\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lactate\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][4]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/dL    475361\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    475361.000000\n",
       "mean         32.570594\n",
       "std          25.540428\n",
       "min           0.000000\n",
       "0.1%          2.000000\n",
       "1%            4.000000\n",
       "5%            7.000000\n",
       "50%          25.000000\n",
       "95%          85.000000\n",
       "99%         121.000000\n",
       "99.9%       169.000000\n",
       "max         305.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BUN\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][5]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units    285339\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    285339.000000\n",
       "mean          7.376181\n",
       "std           0.093822\n",
       "min           0.940000\n",
       "0.1%          6.930000\n",
       "1%            7.090000\n",
       "5%            7.210000\n",
       "50%           7.390000\n",
       "95%           7.500000\n",
       "99%           7.550000\n",
       "99.9%         7.610000\n",
       "max           7.960000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arterial pH\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][6]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K/uL    430106\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    430106.000000\n",
       "mean         11.786931\n",
       "std          21.262093\n",
       "min           0.000000\n",
       "0.1%          0.100000\n",
       "1%            0.300000\n",
       "5%            2.700000\n",
       "50%          10.100000\n",
       "95%          25.200000\n",
       "99%          41.000000\n",
       "99.9%       101.989500\n",
       "max       12500.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WBC\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][7]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g/dL    462063\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    462063.000000\n",
       "mean          9.324117\n",
       "std           1.798835\n",
       "min           0.000000\n",
       "0.1%          4.900000\n",
       "1%            6.300000\n",
       "5%            7.000000\n",
       "50%           9.000000\n",
       "95%          12.700000\n",
       "99%          14.500000\n",
       "99.9%        16.700000\n",
       "max          98.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hemoglobin\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][8]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%    463919\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    463919.000000\n",
       "mean         28.501613\n",
       "std           5.191310\n",
       "min           2.100000\n",
       "0.1%         15.500000\n",
       "1%           19.400000\n",
       "5%           21.600000\n",
       "50%          27.700000\n",
       "95%          38.300000\n",
       "99%          43.900000\n",
       "99.9%        50.708200\n",
       "max          67.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hematocrit\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][9]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mEq/L    499588\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    499588.000000\n",
       "mean          4.108045\n",
       "std           0.632763\n",
       "min           1.000000\n",
       "0.1%          2.500000\n",
       "1%            2.900000\n",
       "5%            3.200000\n",
       "50%           4.000000\n",
       "95%           5.200000\n",
       "99%           6.000000\n",
       "99.9%         7.900000\n",
       "max          12.700000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# potassium\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][10]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mL    561\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count      561.000000\n",
       "mean      1760.192513\n",
       "std       2616.904499\n",
       "min          5.000000\n",
       "0.1%         5.000000\n",
       "1%           6.600000\n",
       "5%         200.000000\n",
       "50%       1400.000000\n",
       "95%       3950.000000\n",
       "99%       6430.000000\n",
       "99.9%    30084.000000\n",
       "max      55550.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# urine output\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][11]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mEq/L    499423\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    499423.000000\n",
       "mean        138.681807\n",
       "std           5.731934\n",
       "min          67.000000\n",
       "0.1%        116.000000\n",
       "1%          125.000000\n",
       "5%          130.000000\n",
       "50%         139.000000\n",
       "95%         148.000000\n",
       "99%         154.000000\n",
       "99.9%       162.000000\n",
       "max         184.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sodium\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][12]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/L    4873\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    4874.000000\n",
       "mean       90.794019\n",
       "std        77.993806\n",
       "min         0.200000\n",
       "0.1%        0.400000\n",
       "1%          0.700000\n",
       "5%          3.200000\n",
       "50%        70.500000\n",
       "95%       248.410000\n",
       "99%       287.427000\n",
       "99.9%     302.303500\n",
       "max       586.600000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CRP\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][13]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: valueuom, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    0.0\n",
       "mean     NaN\n",
       "std      NaN\n",
       "min      NaN\n",
       "0.1%     NaN\n",
       "1%       NaN\n",
       "5%       NaN\n",
       "50%      NaN\n",
       "95%      NaN\n",
       "99%      NaN\n",
       "99.9%    NaN\n",
       "max      NaN\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vent\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.LE[~pd.isna(d_predictor.LE)].ravel()][14]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# it is shown that unit conversion is not needed\n",
    "# anyway we should check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26299168.0, 2171-11-10 12:00:00, 7.656119366529843e+18\n",
      "22607104.0, 2167-10-21 00:43:00, 1.3510798882111488e+18\n",
      "22036881.0, 2140-09-05 15:06:00, 1.7676628537429197e+19\n",
      "20880376.0, 2128-07-28 13:12:00, 6.755399441055744e+18\n",
      "20963681.0, 2177-04-28 19:46:00, 2.251799813685248e+18\n",
      "24808859.0, 2188-10-11 18:06:00, 209999.9999999972\n",
      "24808859.0, 2188-10-11 18:06:00, 1.5762598695796736e+19\n",
      "24535091.0, 2124-05-22 08:00:00, 8.556839292003942e+18\n",
      "25809889.0, 2132-12-29 03:54:00, 4.503599627370496e+16\n",
      "26341885.0, 2130-03-12 06:00:00, 1.5762598695796736e+19\n",
      "24976204.0, 2163-03-27 08:56:00, 4.503599627370496e+18\n",
      "28494482.0, 2138-06-06 19:00:00, 5.62949953421312e+17\n",
      "27199030.0, 2183-01-20 06:13:00, 2.7021597764222976e+18\n",
      "27199030.0, 2183-01-25 08:36:00, 4.503599627370496e+18\n",
      "24855743.0, 2187-10-08 13:49:00, 3.8280596832649216e+18\n",
      "26250746.0, 2147-05-12 22:23:00, 6.530219459687219e+18\n",
      "29186168.0, 2145-04-19 18:10:00, 2.9273397577908224e+18\n",
      "21479712.0, 2115-01-07 16:24:00, 2.9273397577908224e+18\n",
      "23749463.0, 2180-06-10 06:04:00, 7.318349394477056e+18\n",
      "25082757.0, 2113-02-19 10:25:00, 7.656119366529843e+18\n",
      "25082757.0, 2113-03-05 08:12:00, 8.106479329266893e+18\n",
      "25824511.0, 2167-12-07 18:28:00, 5.17913957147607e+18\n",
      "22347201.0, 2184-06-11 16:14:00, 3.602879701896397e+18\n",
      "21302475.0, 2117-10-26 16:00:00, 3.4902897112121344e+18\n",
      "21302475.0, 2117-10-27 15:56:00, 3.377699720527872e+18\n",
      "21129012.0, 2136-09-08 08:17:00, 4.0082036683597414e+18\n",
      "24685101.0, 2174-05-11 11:39:00, 7.205759403792794e+18\n",
      "22745576.0, 2119-09-18 17:11:00, 1.778921852811346e+19\n",
      "27093579.0, 2170-07-05 10:42:00, 5.066549580791808e+18\n",
      "25486927.0, 2170-12-16 21:45:00, 1.3398208891427226e+19\n"
     ]
    }
   ],
   "source": [
    "# urine output outlier handling\n",
    "admissions = pd.read_csv('hosp/admissions.csv')\n",
    "admissions.admittime = pd.to_datetime(admissions.admittime)\n",
    "admissions.dischtime = pd.to_datetime(admissions.dischtime)\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('urin'))&(~pd.isna(d_predictor.LE)), ('LE')].to_numpy()\n",
    "raw_itemid = raw_itemid[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "\n",
    "for adm in df.hadm_id.unique():\n",
    "    tmp_cond = (df.hadm_id == adm) & (df.itemid.isin(tmp_itemid))\n",
    "    part_df = df.loc[tmp_cond].reset_index(drop=True)\n",
    "    tmp_cond = admissions.hadm_id == adm\n",
    "    at, dt = admissions.loc[tmp_cond, ('admittime', 'dischtime')].to_numpy()[0]\n",
    "    for idx, ct in enumerate(part_df.charttime):\n",
    "        if idx == 0:\n",
    "            td = (ct - at)/datetime.timedelta(hours=1)\n",
    "            urine_hr = part_df.loc[idx, 'valuenum'] / (td + sys.float_info.epsilon)\n",
    "        elif idx == part_df.index[-1]:\n",
    "            td = (dt - ct)/datetime.timedelta(hours=1)\n",
    "            urine_hr = part_df.loc[idx, 'valuenum'] / (td + sys.float_info.epsilon)\n",
    "        else: \n",
    "            td = (ct - part_df.loc[idx-1, 'charttime'])/datetime.timedelta(hours=1)\n",
    "            urine_hr = part_df.loc[idx, 'valuenum'] / (td + sys.float_info.epsilon)\n",
    "        \n",
    "        if urine_hr > 1000:\n",
    "            print(f'{adm}, {ct}, {urine_hr}')\n",
    "            tmp_cond = (df.hadm_id == adm) & (df.charttime == ct) & (df.itemid.isin(tmp_itemid))\n",
    "            if td != 0:\n",
    "                df.loc[tmp_cond, 'valuenum'] = 1000*td\n",
    "            else:\n",
    "                df.loc[tmp_cond, 'valuenum'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature, [50825]\n",
      "Bilirubin, [50885, 53089]\n",
      "Platelets, [51265, 51704]\n",
      "Creatinine, [51081]\n",
      "Lactate, [50813, 52442]\n",
      "BUN, [51006, 52647]\n",
      "Arterial pH, [50820]\n",
      "WBC, [51300, 51301, 51755, 51756]\n",
      "Hemoglobin, [50811, 51222, 51640]\n",
      "Hematocrit, [51221, 51638, 51639, 52028]\n",
      "Potassium, [50971, 52610]\n",
      "Sodium, [50983, 52623]\n",
      "3968337 -> 3968001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51301    136\n",
       "50825     62\n",
       "51265     55\n",
       "50885     46\n",
       "50811     15\n",
       "50820     11\n",
       "50971      4\n",
       "50813      2\n",
       "51006      2\n",
       "51222      2\n",
       "50983      1\n",
       "Name: itemid, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier handling (except urine)\n",
    "outlier_criteria = pd.read_csv('processed_data/sepsis/outlier_criteria.csv')\n",
    "drop_idx = []\n",
    "for item in outlier_criteria.features:\n",
    "    raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains(item.lower()[0:4]))&(~pd.isna(d_predictor.LE)), ('LE')].to_numpy()\n",
    "    if len(raw_itemid) != 0:\n",
    "        raw_itemid = raw_itemid[0]\n",
    "        tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "        print(f'{item}, {tmp_itemid}')\n",
    "        \n",
    "        lb, ub = outlier_criteria.loc[outlier_criteria.features.str.lower().str.contains(item.lower()[0:4]), ('lb', 'ub')].to_numpy()[0]\n",
    "        if item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<=, >=', 'features'].str.lower()]: # <=, >=\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum <= lb) | (df.valuenum >= ub)))\n",
    "        elif item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<, >=', 'features'].str.lower()]: # <, >=\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum < lb) | (df.valuenum >= ub)))\n",
    "        elif item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<=, >', 'features'].str.lower()]: # <=, >\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum <= lb) | (df.valuenum > ub)))\n",
    "        elif item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<, >', 'features'].str.lower()]: #<, >\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum < lb) | (df.valuenum > ub)))\n",
    "        drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "print(f'{df.shape[0]} -> {df.iloc[list(set(df.index) - set(drop_idx))].shape[0]}')\n",
    "df.iloc[drop_idx].itemid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_idx).to_csv('processed_data/sepsis/LE_R.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. chartevents processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dirs[2])\n",
    "df.charttime = pd.to_datetime(df.charttime) # for time should be able to calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the d_predictor, choose the item ids for labevents\n",
    "d_predictor = pd.read_csv('processed_data/sepsis/d_predictors.csv')\n",
    "tmp = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()]\n",
    "itemids_CE = []\n",
    "for i in tmp: \n",
    "    itemids_CE += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data to have only predictor relevant rows and relevent columns\n",
    "tmp_cond = df.itemid.isin(itemids_CE)\n",
    "df = df.loc[tmp_cond, ('subject_id', 'hadm_id', 'stay_id', 'charttime', 'storetime', 'itemid', 'valuenum', 'valueuom')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            86.0\n",
       "1           151.0\n",
       "2            90.0\n",
       "3            18.0\n",
       "4             4.0\n",
       "            ...  \n",
       "24348860     87.0\n",
       "24348861     24.0\n",
       "24348862     98.6\n",
       "24348863    143.0\n",
       "24348864    107.0\n",
       "Name: valuenum, Length: 24348865, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if df has result value that can not be type conversed to float.\n",
    "df.iloc[:, -2].astype('float')\n",
    "# we dont have such columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: itemid, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# missing value handling\n",
    "print(df.loc[pd.isna(df.valuenum)].itemid.value_counts())\n",
    "df = df.drop(pd.isna(df.valuenum).index[pd.isna(df.valuenum)]).reset_index(drop=True)\n",
    "# no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Heart rate', 'Respiratory rate', 'Temperature', 'SBP', 'DBP',\n",
       "       'CVP', 'PaO2', 'FiO2', 'GCS', 'Bilirubin', 'Platelets',\n",
       "       'Creatinine', 'Lactate', 'BUN', 'Arterial pH', 'WBC', 'PaCO2',\n",
       "       'Hemoglobin', 'Hematocrit', 'Potassium', 'Sodium',\n",
       "       'C Reactive Protein', 'Weight', 'Height'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit conversion\n",
    "# check which item may need unit conversion \n",
    "d_predictor['items'][~pd.isna(d_predictor.CE)].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpm    3880579\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    3.880579e+06\n",
       "mean     9.135713e+01\n",
       "std      5.079131e+03\n",
       "min     -2.413950e+05\n",
       "0.1%     3.800000e+01\n",
       "1%       5.200000e+01\n",
       "5%       6.000000e+01\n",
       "50%      8.800000e+01\n",
       "95%      1.210000e+02\n",
       "99%      1.370000e+02\n",
       "99.9%    1.610000e+02\n",
       "max      1.000000e+07\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# heart rate\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][0]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insp/min    4296278\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    4.296278e+06\n",
       "mean     2.150436e+01\n",
       "std      1.142256e+03\n",
       "min     -1.000000e+00\n",
       "0.1%     0.000000e+00\n",
       "1%       8.000000e+00\n",
       "5%       1.200000e+01\n",
       "50%      2.000000e+01\n",
       "95%      3.200000e+01\n",
       "99%      3.800000e+01\n",
       "99.9%    4.872300e+01\n",
       "max      2.355560e+06\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# respatory rate \n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][1]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "°F    938609\n",
      "°C    156190\n",
      "Name: valueuom, dtype: int64\n",
      "°C    1094799\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.094799e+06\n",
       "mean     3.707046e+01\n",
       "std      3.602458e+00\n",
       "min     -7.327778e+01\n",
       "0.1%     3.280000e+01\n",
       "1%       3.516667e+01\n",
       "5%       3.594444e+01\n",
       "50%      3.700000e+01\n",
       "95%      3.838889e+01\n",
       "99%      3.922222e+01\n",
       "99.9%    4.005556e+01\n",
       "max      6.490000e+02\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temperature\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][2]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# we should convert the unit F to C\n",
    "tmp_cond = df.itemid.isin([tmp_itemid[0]]) # F\n",
    "df.loc[tmp_cond, 'valuenum'] = np.array((df.valuenum[tmp_cond]-32)*5/9)\n",
    "df.loc[tmp_cond, 'valueuom'] = '°C'\n",
    "df.loc[tmp_cond, 'itemid'] = tmp_itemid[1]\n",
    "# check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmHg    3982108\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    3.982108e+06\n",
       "mean     1.186671e+02\n",
       "std      5.101672e+02\n",
       "min     -6.900000e+01\n",
       "0.1%     4.800000e+01\n",
       "1%       7.300000e+01\n",
       "5%       8.600000e+01\n",
       "50%      1.160000e+02\n",
       "95%      1.600000e+02\n",
       "99%      1.800000e+02\n",
       "99.9%    2.070000e+02\n",
       "max      1.003070e+06\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SBP\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][3]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmHg    3981338\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    3.981338e+06\n",
       "mean     6.302683e+01\n",
       "std      2.782556e+02\n",
       "min     -4.000000e+01\n",
       "0.1%     2.100000e+01\n",
       "1%       3.300000e+01\n",
       "5%       4.100000e+01\n",
       "50%      6.000000e+01\n",
       "95%      8.900000e+01\n",
       "99%      1.050000e+02\n",
       "99.9%    1.370000e+02\n",
       "max      1.141000e+05\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBP\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][4]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmHg    485818\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    485818.000000\n",
       "mean         16.476485\n",
       "std          37.057964\n",
       "min         -41.000000\n",
       "0.1%         -6.000000\n",
       "1%            0.000000\n",
       "5%            3.000000\n",
       "50%          12.000000\n",
       "95%          24.000000\n",
       "99%         271.000000\n",
       "99.9%       351.000000\n",
       "max        7785.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CVP\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][5]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmHg    206402\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    206402.000000\n",
       "mean        197.904977\n",
       "std        8803.314368\n",
       "min         -17.000000\n",
       "0.1%         31.000000\n",
       "1%           50.000000\n",
       "5%           63.000000\n",
       "50%         103.000000\n",
       "95%         245.000000\n",
       "99%         407.000000\n",
       "99.9%       516.000000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paO2\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][6]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: valueuom, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    645842.000000\n",
       "mean         48.021418\n",
       "std          29.212437\n",
       "min           0.000000\n",
       "0.1%          2.000000\n",
       "1%           30.000000\n",
       "5%           30.000000\n",
       "50%          40.000000\n",
       "95%          90.000000\n",
       "99%         100.000000\n",
       "99.9%       100.000000\n",
       "max       10050.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fiO2\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][7]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: valueuom, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2.777671e+06\n",
       "mean     3.597729e+00\n",
       "std      1.859882e+00\n",
       "min      1.000000e+00\n",
       "0.1%     1.000000e+00\n",
       "1%       1.000000e+00\n",
       "5%       1.000000e+00\n",
       "50%      4.000000e+00\n",
       "95%      6.000000e+00\n",
       "99%      6.000000e+00\n",
       "99.9%    6.000000e+00\n",
       "max      6.000000e+00\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GCS\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][8]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])\n",
    "# GCS doesnt need outlier deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/dL    81787\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count     81794.000000\n",
       "mean         53.325510\n",
       "std        6992.930629\n",
       "min           0.000000\n",
       "0.1%          0.100000\n",
       "1%            0.200000\n",
       "5%            0.200000\n",
       "50%           1.200000\n",
       "95%          21.500000\n",
       "99%          38.600000\n",
       "99.9%        55.200000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bili\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][9]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K/uL    235008\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    235054.000000\n",
       "mean        347.018252\n",
       "std       12024.533324\n",
       "min           0.000000\n",
       "0.1%          6.000000\n",
       "1%           15.000000\n",
       "5%           35.000000\n",
       "50%         173.000000\n",
       "95%         476.000000\n",
       "99%         685.000000\n",
       "99.9%      1031.947000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# platelets\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][10]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/dL    264516\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    264563.000000\n",
       "mean         50.811621\n",
       "std        7009.646603\n",
       "min          -0.100000\n",
       "0.1%          0.100000\n",
       "1%            0.300000\n",
       "5%            0.400000\n",
       "50%           1.200000\n",
       "95%           4.700000\n",
       "99%           7.600000\n",
       "99.9%        13.043800\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creatinine\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][11]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmol/L    159189\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.592050e+05\n",
       "mean     1.425838e+02\n",
       "std      1.192117e+04\n",
       "min      0.000000e+00\n",
       "0.1%     4.000000e-01\n",
       "1%       6.000000e-01\n",
       "5%       8.000000e-01\n",
       "50%      1.800000e+00\n",
       "95%      7.900000e+00\n",
       "99%      1.430000e+01\n",
       "99.9%    2.150000e+01\n",
       "max      1.276100e+06\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lactate\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][12]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/dL    263964\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    264035.000000\n",
       "mean        167.981567\n",
       "std       11512.262599\n",
       "min           0.000000\n",
       "0.1%          2.000000\n",
       "1%            4.000000\n",
       "5%            8.000000\n",
       "50%          27.000000\n",
       "95%          91.000000\n",
       "99%         128.000000\n",
       "99.9%       182.000000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bun\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][13]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units    211087\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    211268.000000\n",
       "mean         92.579310\n",
       "std        9229.927267\n",
       "min           0.000000\n",
       "0.1%          6.940000\n",
       "1%            7.090000\n",
       "5%            7.210000\n",
       "50%           7.390000\n",
       "95%           7.510000\n",
       "99%           7.550000\n",
       "99.9%         7.610000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arterial pH\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][14]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K/uL    229771\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    229813.000000\n",
       "mean        178.721353\n",
       "std       12857.704237\n",
       "min           0.000000\n",
       "0.1%          0.100000\n",
       "1%            0.800000\n",
       "5%            3.900000\n",
       "50%          11.500000\n",
       "95%          28.400000\n",
       "99%          45.100000\n",
       "99.9%       121.000000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wbc\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][15]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmHg    206402\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    206402.000000\n",
       "mean        119.203264\n",
       "std        8803.778278\n",
       "min           0.000000\n",
       "0.1%         16.000000\n",
       "1%           22.000000\n",
       "5%           28.000000\n",
       "50%          40.000000\n",
       "95%          61.000000\n",
       "99%          79.000297\n",
       "99.9%       110.000000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paco2\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][16]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g/dl    250969\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    250969.000000\n",
       "mean        136.852267\n",
       "std       11291.031957\n",
       "min           0.000000\n",
       "0.1%          4.700000\n",
       "1%            6.200000\n",
       "5%            7.000000\n",
       "50%           9.100000\n",
       "95%          12.700000\n",
       "99%          14.600000\n",
       "99.9%        16.900000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hemoglobin\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][17]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%    278036\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2.781780e+05\n",
       "mean     1.507615e+02\n",
       "std      1.138215e+04\n",
       "min      0.000000e+00\n",
       "0.1%     1.420000e+01\n",
       "1%       1.910000e+01\n",
       "5%       2.160000e+01\n",
       "50%      2.770000e+01\n",
       "95%      3.830000e+01\n",
       "99%      4.410000e+01\n",
       "99.9%    5.130000e+01\n",
       "max      2.011200e+06\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hematocrit\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][18]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mEq/L    343735\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    343806.000000\n",
       "mean         59.381962\n",
       "std        7433.724983\n",
       "min           0.000000\n",
       "0.1%          2.300000\n",
       "1%            2.900000\n",
       "5%            3.200000\n",
       "50%           4.000000\n",
       "95%           5.300000\n",
       "99%           6.200000\n",
       "99.9%         8.100000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# potassium\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][19]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mEq/L    284103\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    284205.000000\n",
       "mean        181.581584\n",
       "std        6496.891197\n",
       "min          -4.000000\n",
       "0.1%        115.000000\n",
       "1%          125.000000\n",
       "5%          130.000000\n",
       "50%         139.000000\n",
       "95%         149.000000\n",
       "99%         156.000000\n",
       "99.9%       165.000000\n",
       "max      999999.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sodium\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][20]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg/L    1770\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1770.000000\n",
       "mean      113.217119\n",
       "std        83.780406\n",
       "min         0.100000\n",
       "0.1%        0.176900\n",
       "1%          1.538000\n",
       "5%          5.890000\n",
       "50%       100.300000\n",
       "95%       266.350000\n",
       "99%       300.000000\n",
       "99.9%     386.997900\n",
       "max       531.300000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CRP\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][21]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kg    160044\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    160044.000000\n",
       "mean         90.398089\n",
       "std          26.723832\n",
       "min         -95.900000\n",
       "0.1%          0.000000\n",
       "1%           44.500000\n",
       "5%           56.400000\n",
       "50%          87.400000\n",
       "95%         134.400000\n",
       "99%         170.000000\n",
       "99.9%       285.000000\n",
       "max         876.000000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weight\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][22]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# check the distribution of the data\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inch    13462\n",
      "cm      13462\n",
      "Name: valueuom, dtype: int64\n",
      "cm    26924\n",
      "Name: valueuom, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    2.692400e+04\n",
       "mean     3.242422e+02\n",
       "std      1.806039e+04\n",
       "min      0.000000e+00\n",
       "0.1%     1.598060e+01\n",
       "1%       1.400000e+02\n",
       "5%       1.520000e+02\n",
       "50%      1.700000e+02\n",
       "95%      1.854200e+02\n",
       "99%      1.915929e+02\n",
       "99.9%    2.010000e+02\n",
       "max      2.095680e+06\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Height\n",
    "tmp_itemid = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.CE[~pd.isna(d_predictor.CE)].ravel()][23]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "# we should convert the unit F to C\n",
    "tmp_cond = df.itemid.isin([tmp_itemid[0]]) # inch\n",
    "df.loc[tmp_cond, 'valuenum'] = inch_to_cm(df.valuenum[tmp_cond])\n",
    "df.loc[tmp_cond, 'valueuom'] = 'cm'\n",
    "df.loc[tmp_cond, 'itemid'] = tmp_itemid[1]\n",
    "# check the distribution of the data\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "print(df.loc[tmp_cond].valueuom.value_counts())\n",
    "df.loc[tmp_cond].valuenum.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart rate, [220045]\n",
      "Respiratory rate, [224690, 220210]\n",
      "Temperature, [223761, 223762]\n",
      "SBP, [220050, 225309, 220179]\n",
      "DBP, [220051, 225310, 220180]\n",
      "CVP, [220074]\n",
      "PaO2, [220224]\n",
      "FiO2, [223835]\n",
      "Bilirubin, [225690]\n",
      "Platelets, [227457]\n",
      "Creatinine, [220615]\n",
      "Lactate, [225668]\n",
      "BUN, [225624]\n",
      "Arterial pH, [223830]\n",
      "WBC, [220546]\n",
      "PaCO2, [220235]\n",
      "Hemoglobin, [220228]\n",
      "Hematocrit, [226540, 220545]\n",
      "Potassium, [227442, 227464]\n",
      "Sodium, [220645]\n",
      "Height, [226707, 226730]\n",
      "Weight, [224639]\n",
      "24348865 -> 24313002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "220210    16107\n",
       "220074    11942\n",
       "223835     1582\n",
       "220045     1510\n",
       "223762     1171\n",
       "224690      965\n",
       "220051      548\n",
       "220180      488\n",
       "224639      325\n",
       "220224      320\n",
       "220050      134\n",
       "220179      120\n",
       "220546      114\n",
       "225310       90\n",
       "220228       52\n",
       "220545       46\n",
       "227457       46\n",
       "225624       38\n",
       "225690       34\n",
       "220235       31\n",
       "227464       29\n",
       "220645       28\n",
       "223830       27\n",
       "227442       25\n",
       "225668       23\n",
       "226540       22\n",
       "225309       21\n",
       "220615       17\n",
       "226730        8\n",
       "Name: itemid, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier handling (except urine)\n",
    "outlier_criteria = pd.read_csv('processed_data/sepsis/outlier_criteria.csv')\n",
    "drop_idx = []\n",
    "for item in outlier_criteria.features:\n",
    "    raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains(item.lower()[0:4]))&(~pd.isna(d_predictor.CE)), ('CE')].to_numpy()\n",
    "    if len(raw_itemid) != 0:\n",
    "        raw_itemid = raw_itemid[0]\n",
    "        tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "        print(f'{item}, {tmp_itemid}')\n",
    "        \n",
    "        lb, ub = outlier_criteria.loc[outlier_criteria.features.str.lower().str.contains(item.lower()[0:4]), ('lb', 'ub')].to_numpy()[0]\n",
    "        if item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<=, >=', 'features'].str.lower()]: # <=, >=\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum <= lb) | (df.valuenum >= ub)))\n",
    "        elif item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<, >=', 'features'].str.lower()]: # <, >=\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum < lb) | (df.valuenum >= ub)))\n",
    "        elif item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<=, >', 'features'].str.lower()]: # <=, >\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum <= lb) | (df.valuenum > ub)))\n",
    "        elif item.lower()[0:4] in [i[0:4] for i in outlier_criteria.loc[outlier_criteria.criteria == '<, >', 'features'].str.lower()]: #<, >\n",
    "            tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.valuenum < lb) | (df.valuenum > ub)))\n",
    "        drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "print(f'{df.shape[0]} -> {df.iloc[list(set(df.index) - set(drop_idx))].shape[0]}')\n",
    "df.iloc[drop_idx].itemid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_idx).to_csv('processed_data/sepsis/CE_R.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. inputevents processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dirs[3])\n",
    "df.starttime = pd.to_datetime(df.starttime) # for time should be able to calculated\n",
    "df.endtime = pd.to_datetime(df.endtime) # for time should be able to calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the d_predictor, choose the item ids for labevents\n",
    "d_predictor = pd.read_csv('processed_data/sepsis/d_predictors.csv')\n",
    "tmp = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.IE[~pd.isna(d_predictor.IE)].ravel()]\n",
    "itemids_IE = []\n",
    "for i in tmp: \n",
    "    itemids_IE += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data to have only predictor relevant rows and relevent columns\n",
    "tmp_cond = df.itemid.isin(itemids_IE)\n",
    "df = df.loc[tmp_cond, ('subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'itemid', 'amount', 'amountuom', 'rate', 'rateuom', 'patientweight')].reset_index(drop=True)\n",
    "# 6179964 -> 3409268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          71.2\n",
       "1          71.2\n",
       "2          71.2\n",
       "3          71.2\n",
       "4          71.2\n",
       "           ... \n",
       "3409263    94.0\n",
       "3409264    94.0\n",
       "3409265    94.0\n",
       "3409266    94.0\n",
       "3409267    94.0\n",
       "Name: patientweight, Length: 3409268, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if df has result value that can not be type conversed to float.\n",
    "df.loc[:, 'amount'].astype('float')\n",
    "df.loc[:, 'rate'].astype('float')\n",
    "df.loc[:, 'patientweight'].astype('float')\n",
    "# we dont have such columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: itemid, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# missing value handling for only amount, because fluid or patient weight can have nan rate.\n",
    "print(df.loc[pd.isna(df.amount)].itemid.value_counts())\n",
    "df = df.drop(pd.isna(df.amount).index[pd.isna(df.amount)]).reset_index(drop=True)\n",
    "# no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Epinephrine', 'Dopamine', 'Dobutamine', 'Norepinephrine',\n",
       "       'Phenylephrine', 'Vasopressin', 'Fluid'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit conversion\n",
    "# check which item may need unit conversion \n",
    "d_predictor['items'][~pd.isna(d_predictor.IE)].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml       2926487\n",
      "mg        460946\n",
      "units      21796\n",
      "L             35\n",
      "mcg            3\n",
      "cm3            1\n",
      "Name: amountuom, dtype: int64\n",
      "mL/hour       1654125\n",
      "mcg/kg/min     460947\n",
      "units/hour      21793\n",
      "mL/min            135\n",
      "units/min           3\n",
      "mg/kg/min           2\n",
      "Name: rateuom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.amountuom.value_counts())\n",
    "print(df.rateuom.value_counts())\n",
    "# for amount, we will try to use unit as ml and mg\n",
    "# for rate of vasopressor, we will try to use mcg/kg/min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg     14584\n",
      "mcg        3\n",
      "Name: amountuom, dtype: int64\n",
      "count    14587.000000\n",
      "mean         1.180257\n",
      "std          3.317072\n",
      "min          0.000112\n",
      "0.1%         0.001339\n",
      "1%           0.005483\n",
      "5%           0.019017\n",
      "50%          0.380539\n",
      "95%          6.354799\n",
      "99%          8.000000\n",
      "99.9%       16.000001\n",
      "max        234.920636\n",
      "Name: amount, dtype: float64\n",
      "mcg/kg/min    14587\n",
      "Name: rateuom, dtype: int64\n",
      "count    14587.000000\n",
      "mean         0.181074\n",
      "std          0.564599\n",
      "min          0.001000\n",
      "0.1%         0.005001\n",
      "1%           0.009993\n",
      "5%           0.010014\n",
      "50%          0.060027\n",
      "95%          0.765298\n",
      "99%          2.042211\n",
      "99.9%        3.548371\n",
      "max         41.142862\n",
      "Name: rate, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    3.000000\n",
       "mean     0.165291\n",
       "std      0.092031\n",
       "min      0.060952\n",
       "25%      0.130476\n",
       "50%      0.200000\n",
       "75%      0.217460\n",
       "max      0.234921\n",
       "Name: amount, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Epinephrine\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('epin'.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "# amount unit check\n",
    "print(df.loc[tmp_cond].amountuom.value_counts())\n",
    "# amount distribution check\n",
    "print(df.loc[tmp_cond].amount.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# rate unit check\n",
    "print(df.loc[tmp_cond].rateuom.value_counts())\n",
    "# rate distribution check\n",
    "print(df.loc[tmp_cond].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "\n",
    "# convert mcg to mg\n",
    "tmp_cond = (df.itemid.isin(tmp_itemid)) & (df.amountuom == 'mcg')\n",
    "df.loc[tmp_cond, 'amount'] = mcg_to_mg(df.loc[tmp_cond, 'amount'])\n",
    "df.loc[tmp_cond, 'amountuom'] = 'mg'\n",
    "\n",
    "df.loc[tmp_cond, 'amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg    10850\n",
      "Name: amountuom, dtype: int64\n",
      "count    10850.000000\n",
      "mean        88.824006\n",
      "std        126.117236\n",
      "min          0.017602\n",
      "0.1%         0.146699\n",
      "1%           0.639752\n",
      "5%           2.015422\n",
      "50%         33.048929\n",
      "95%        395.840018\n",
      "99%        400.000098\n",
      "99.9%      800.000003\n",
      "max        801.663511\n",
      "Name: amount, dtype: float64\n",
      "mcg/kg/min    10850\n",
      "Name: rateuom, dtype: int64\n",
      "count    10850.000000\n",
      "mean         8.486185\n",
      "std         52.284165\n",
      "min          0.200020\n",
      "0.1%         0.500050\n",
      "1%           1.000241\n",
      "5%           2.000000\n",
      "50%          5.962188\n",
      "95%         19.975521\n",
      "99%         20.307962\n",
      "99.9%      119.018174\n",
      "max       4000.000000\n",
      "Name: rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Dopamin\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('dopa'.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "# amount unit check\n",
    "print(df.loc[tmp_cond].amountuom.value_counts())\n",
    "# amount distribution check\n",
    "print(df.loc[tmp_cond].amount.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# rate unit check\n",
    "print(df.loc[tmp_cond].rateuom.value_counts())\n",
    "# rate distribution check\n",
    "print(df.loc[tmp_cond].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# no need to convert units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg    6200\n",
      "Name: amountuom, dtype: int64\n",
      "count    6200.000000\n",
      "mean      145.686638\n",
      "std       137.140404\n",
      "min         0.014964\n",
      "0.1%        0.187120\n",
      "1%          0.600091\n",
      "5%          2.704009\n",
      "50%       117.054321\n",
      "95%       460.631039\n",
      "99%       500.000011\n",
      "99.9%     999.120445\n",
      "max      1000.000037\n",
      "Name: amount, dtype: float64\n",
      "mcg/kg/min    6200\n",
      "Name: rateuom, dtype: int64\n",
      "count    6200.000000\n",
      "mean        5.228331\n",
      "std         4.121954\n",
      "min         0.080024\n",
      "0.1%        0.300017\n",
      "1%          0.500152\n",
      "5%          1.500093\n",
      "50%         4.999570\n",
      "95%        10.348368\n",
      "99%        20.030847\n",
      "99.9%      32.473437\n",
      "max       135.869563\n",
      "Name: rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Dobutamin\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('dobu'.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "# amount unit check\n",
    "print(df.loc[tmp_cond].amountuom.value_counts())\n",
    "# amount distribution check\n",
    "print(df.loc[tmp_cond].amount.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# rate unit check\n",
    "print(df.loc[tmp_cond].rateuom.value_counts())\n",
    "# rate distribution check\n",
    "print(df.loc[tmp_cond].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# no need to convert units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg    286862\n",
      "Name: amountuom, dtype: int64\n",
      "count    286862.000000\n",
      "mean          1.240004\n",
      "std           2.130145\n",
      "min           0.000021\n",
      "0.1%          0.002106\n",
      "1%            0.008902\n",
      "5%            0.031086\n",
      "50%           0.452874\n",
      "95%           5.668001\n",
      "99%           9.754658\n",
      "99.9%        16.000001\n",
      "max          36.727881\n",
      "Name: amount, dtype: float64\n",
      "mcg/kg/min    286860\n",
      "mg/kg/min          2\n",
      "Name: rateuom, dtype: int64\n",
      "count    286862.000000\n",
      "mean          0.158394\n",
      "std           0.895220\n",
      "min           0.000200\n",
      "0.1%          0.009969\n",
      "1%            0.010059\n",
      "5%            0.020031\n",
      "50%           0.100110\n",
      "95%           0.407393\n",
      "99%           0.514064\n",
      "99.9%         2.025534\n",
      "max         359.550595\n",
      "Name: rate, dtype: float64\n",
      "mcg/kg/min    286862\n",
      "Name: rateuom, dtype: int64\n",
      "count    286862.000000\n",
      "mean          0.158604\n",
      "std           0.898712\n",
      "min           0.000200\n",
      "0.1%          0.009969\n",
      "1%            0.010059\n",
      "5%            0.020031\n",
      "50%           0.100110\n",
      "95%           0.407414\n",
      "99%           0.514106\n",
      "99.9%         2.043738\n",
      "max         359.550595\n",
      "Name: rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Norepinephrine\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('nore'.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "# amount unit check\n",
    "print(df.loc[tmp_cond].amountuom.value_counts())\n",
    "# amount distribution check\n",
    "print(df.loc[tmp_cond].amount.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# rate unit check\n",
    "print(df.loc[tmp_cond].rateuom.value_counts())\n",
    "# rate distribution check\n",
    "print(df.loc[tmp_cond].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# need to convert unit of rate\n",
    "\n",
    "tmp_cond = (df.itemid.isin(tmp_itemid)) & (df.rateuom =='mg/kg/min')\n",
    "df.loc[tmp_cond, 'rate'] = np.array(df.loc[tmp_cond].rate*1000)\n",
    "df.loc[tmp_cond, 'rateuom'] = 'mcg/kg/min'\n",
    "\n",
    "print(df.loc[(df.itemid.isin(tmp_itemid))].rateuom.value_counts())\n",
    "print(df.loc[(df.itemid.isin(tmp_itemid))].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg    142450\n",
      "Name: amountuom, dtype: int64\n",
      "count    142450.000000\n",
      "mean         11.852782\n",
      "std          24.738890\n",
      "min          -0.474000\n",
      "0.1%          0.019759\n",
      "1%            0.083810\n",
      "5%            0.289041\n",
      "50%           4.032292\n",
      "95%          49.657203\n",
      "99%         133.192845\n",
      "99.9%       240.000011\n",
      "max         274.464045\n",
      "Name: amount, dtype: float64\n",
      "mcg/kg/min    142450\n",
      "Name: rateuom, dtype: int64\n",
      "count    142450.000000\n",
      "mean          1.603521\n",
      "std           5.202831\n",
      "min          -5.724638\n",
      "0.1%          0.050007\n",
      "1%            0.100087\n",
      "5%            0.250251\n",
      "50%           1.001640\n",
      "95%           4.301075\n",
      "99%           5.098212\n",
      "99.9%        16.874231\n",
      "max         880.058706\n",
      "Name: rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Phenylephrine\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('phen'.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "# amount unit check\n",
    "print(df.loc[tmp_cond].amountuom.value_counts())\n",
    "# amount distribution check\n",
    "print(df.loc[tmp_cond].amount.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# rate unit check\n",
    "print(df.loc[tmp_cond].rateuom.value_counts())\n",
    "# rate distribution check\n",
    "print(df.loc[tmp_cond].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# need to convert unit of rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units    21796\n",
      "Name: amountuom, dtype: int64\n",
      "count    21796.000000\n",
      "mean        20.297584\n",
      "std         20.308966\n",
      "min          0.002078\n",
      "0.1%         0.020000\n",
      "1%           0.100000\n",
      "5%           0.380886\n",
      "50%         13.884924\n",
      "95%         40.000002\n",
      "99%         99.879998\n",
      "99.9%      100.000004\n",
      "max        399.999997\n",
      "Name: amount, dtype: float64\n",
      "units/hour    21793\n",
      "units/min         3\n",
      "Name: rateuom, dtype: int64\n",
      "count    21796.000000\n",
      "mean         2.496476\n",
      "std         17.064405\n",
      "min          0.016635\n",
      "0.1%         0.240000\n",
      "1%           0.800009\n",
      "5%           1.200000\n",
      "50%          2.400000\n",
      "95%          3.605508\n",
      "99%          4.275367\n",
      "99.9%       31.356483\n",
      "max       2400.000000\n",
      "Name: rate, dtype: float64\n",
      "units/hour    21796\n",
      "Name: rateuom, dtype: int64\n",
      "count    21796.000000\n",
      "mean         2.497018\n",
      "std         17.064392\n",
      "min          0.016635\n",
      "0.1%         0.247928\n",
      "1%           0.800084\n",
      "5%           1.200000\n",
      "50%          2.400000\n",
      "95%          3.605518\n",
      "99%          4.280669\n",
      "99.9%       31.356483\n",
      "max       2400.000000\n",
      "Name: rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Vasopressin\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('vaso'.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "# amount unit check\n",
    "print(df.loc[tmp_cond].amountuom.value_counts())\n",
    "# amount distribution check\n",
    "print(df.loc[tmp_cond].amount.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# rate unit check\n",
    "print(df.loc[tmp_cond].rateuom.value_counts())\n",
    "# rate distribution check\n",
    "print(df.loc[tmp_cond].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "\n",
    "# need to convert unit of rate\n",
    "tmp_cond = (df.itemid.isin(tmp_itemid)) & (df.rateuom =='units/min')\n",
    "df.loc[tmp_cond, 'rate'] = np.array(df.loc[tmp_cond].rate*60)\n",
    "df.loc[tmp_cond, 'rateuom'] = 'units/hour'\n",
    "print(df.loc[(df.itemid.isin(tmp_itemid))].rateuom.value_counts())\n",
    "print(df.loc[(df.itemid.isin(tmp_itemid))].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml     2926487\n",
      "L           35\n",
      "cm3          1\n",
      "Name: amountuom, dtype: int64\n",
      "count    2.926523e+06\n",
      "mean     1.255659e+02\n",
      "std      2.975340e+02\n",
      "min     -1.058330e+01\n",
      "0.1%     4.260528e-02\n",
      "1%       4.952292e-01\n",
      "5%       2.301716e+00\n",
      "50%      5.000000e+01\n",
      "95%      5.000000e+02\n",
      "99%      1.000000e+03\n",
      "99.9%    3.500000e+03\n",
      "max      1.228990e+05\n",
      "Name: amount, dtype: float64\n",
      "mL/hour    1654125\n",
      "mL/min         135\n",
      "Name: rateuom, dtype: int64\n",
      "count    1.654260e+06\n",
      "mean     4.485794e+01\n",
      "std      1.716677e+02\n",
      "min     -1.185000e+02\n",
      "0.1%     4.973477e-01\n",
      "1%       7.000369e-01\n",
      "5%       2.000000e+00\n",
      "50%      1.615557e+01\n",
      "95%      1.500000e+02\n",
      "99%      5.000000e+02\n",
      "99.9%    9.999999e+02\n",
      "max      6.000000e+04\n",
      "Name: rate, dtype: float64\n",
      "mL/hour    1654260\n",
      "Name: rateuom, dtype: int64\n",
      "count    1.654260e+06\n",
      "mean     4.501024e+01\n",
      "std      1.750986e+02\n",
      "min     -1.185000e+02\n",
      "0.1%     4.985045e-01\n",
      "1%       7.001764e-01\n",
      "5%       2.000000e+00\n",
      "50%      1.615713e+01\n",
      "95%      1.500000e+02\n",
      "99%      5.000000e+02\n",
      "99.9%    9.999999e+02\n",
      "max      6.000000e+04\n",
      "Name: rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fluid\n",
    "raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains('fluid'.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "tmp_cond = df.itemid.isin(tmp_itemid)\n",
    "# amount unit check\n",
    "print(df.loc[tmp_cond].amountuom.value_counts())\n",
    "# amount distribution check\n",
    "print(df.loc[tmp_cond].amount.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "# rate unit check\n",
    "print(df.loc[tmp_cond].rateuom.value_counts())\n",
    "# rate distribution check\n",
    "print(df.loc[tmp_cond].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))\n",
    "\n",
    "# need to convert unit of amount and rate\n",
    "tmp_cond = (df.itemid.isin(tmp_itemid)) & (df.amountuom =='cm3')\n",
    "df.loc[tmp_cond, 'amountuom'] = 'ml'\n",
    "tmp_cond = (df.itemid.isin(tmp_itemid)) & (df.amountuom =='L')\n",
    "df.loc[tmp_cond, 'amount'] = np.array(df.loc[tmp_cond, 'amount']*1000)\n",
    "df.loc[tmp_cond, 'amountuom'] = 'ml'\n",
    "\n",
    "tmp_cond = (df.itemid.isin(tmp_itemid)) & (df.rateuom == 'mL/min')\n",
    "df.loc[tmp_cond, 'rate'] = np.array(df.loc[tmp_cond].rate*60)\n",
    "df.loc[tmp_cond, 'rateuom'] = 'mL/hour'\n",
    "print(df.loc[(df.itemid.isin(tmp_itemid))].rateuom.value_counts())\n",
    "print(df.loc[(df.itemid.isin(tmp_itemid))].rate.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier handling for patient weight\n",
    "lb = 0\n",
    "ub = 250\n",
    "\n",
    "tmp_cond = (df.patientweight < lb) | (df.patientweight > ub)\n",
    "drop_idx = tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "df.loc[drop_idx].patientweight.describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])\n",
    "\n",
    "df.loc[drop_idx, 'patientweight'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epinephrine, [221289]\n",
      "Dopamine, [221662]\n",
      "Dobutamine, [221653]\n",
      "Norepinephrine, [221906]\n",
      "Phenylephrine, [221749, 229630, 229632]\n",
      "Vasopressin, [222315]\n",
      "Fluid, [220949, 220950, 220952, 225158, 225159, 225161, 225828, 225797, 225799, 225823, 225825, 225827, 225830, 226089, 225941, 225943, 225944, 226361, 226363, 226364, 226375, 226377, 226452, 226453, 227533, 228140, 228141, 228142, 228341, 220955, 220967, 220968, 220953]\n",
      "3409268 -> 3403942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "226361    1679\n",
       "226364     938\n",
       "225158     789\n",
       "221906     557\n",
       "225828     337\n",
       "220949     284\n",
       "221749     263\n",
       "225943     131\n",
       "226375      70\n",
       "222315      44\n",
       "226089      40\n",
       "221289      28\n",
       "225823      25\n",
       "221662      22\n",
       "225159      20\n",
       "226363      19\n",
       "225944      17\n",
       "229630      17\n",
       "221653      13\n",
       "225799       7\n",
       "226452       7\n",
       "225161       6\n",
       "229632       5\n",
       "225825       3\n",
       "226453       2\n",
       "225827       2\n",
       "220950       1\n",
       "Name: itemid, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# outlier handling\n",
    "drop_idx = []\n",
    "for item in d_predictor.loc[(~pd.isna(d_predictor.IE)), ('items')].tolist():\n",
    "    raw_itemid = d_predictor.loc[(d_predictor['items'].str.lower().str.contains(item.lower()[0:4]))&(~pd.isna(d_predictor.IE)), ('IE')].to_numpy()[0]\n",
    "    tmp_itemid = np.array(raw_itemid.split(',')).astype('int').tolist() if (str(raw_itemid).__contains__(',')) else [int(raw_itemid)]\n",
    "    print(f'{item}, {tmp_itemid}')\n",
    "    \n",
    "    lb = 0 \n",
    "    ub = df.loc[df.itemid.isin(tmp_itemid), 'amount'].describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])['99.9%']\n",
    "    tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.amount < lb) | (df.amount > ub)))\n",
    "    drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "    ub = df.loc[df.itemid.isin(tmp_itemid), 'rate'].describe(percentiles=[i/100 for i in [0.1, 1, 5, 95, 99, 99.9]])['99.9%']\n",
    "    tmp_cond = ((df.itemid.isin(tmp_itemid)) & ((df.rate < lb) | (df.rate > ub)))\n",
    "    drop_idx += tmp_cond.index[tmp_cond].to_list()\n",
    "\n",
    "print(f'{df.shape[0]} -> {df.iloc[list(set(df.index) - set(drop_idx))].shape[0]}')\n",
    "df.iloc[list(set(drop_idx))].itemid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(drop_idx).to_csv('processed_data/sepsis/IE_R.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. outputevents processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hadm_id', 'stay_id', 'charttime', 'storetime', 'itemid',\n",
       "       'value', 'valueuom'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dirs[4])\n",
    "df.charttime = pd.to_datetime(df.charttime) # for time should be able to calculated\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the d_predictor, choose the item ids for labevents\n",
    "d_predictor = pd.read_csv('processed_data/sepsis/d_predictors.csv')\n",
    "tmp = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.OE[~pd.isna(d_predictor.OE)].ravel()]\n",
    "itemids_OE = []\n",
    "for i in tmp: \n",
    "    itemids_OE += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data to have only predictor relevant rows and relevent columns\n",
    "tmp_cond = df.itemid.isin(itemids_OE)\n",
    "df = df.loc[tmp_cond, ('subject_id', 'hadm_id', 'stay_id', 'charttime', 'itemid', 'value', 'valueuom')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          100.0\n",
       "1          120.0\n",
       "2          300.0\n",
       "3          600.0\n",
       "4          275.0\n",
       "           ...  \n",
       "2050470     80.0\n",
       "2050471    100.0\n",
       "2050472     55.0\n",
       "2050473    120.0\n",
       "2050474    325.0\n",
       "Name: value, Length: 2050475, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if df has result value that can not be type conversed to float.\n",
    "df.iloc[:, -2].astype('float')\n",
    "# we dont have such columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: itemid, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# missing value handling for only amount, because fluid can have nan rate\n",
    "print(df.loc[pd.isna(df.value)].itemid.value_counts())\n",
    "# no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml    2050475\n",
      "Name: valueuom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# unit conversion\n",
    "print(df.valueuom.value_counts())\n",
    "# no need for unit conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25494/25494 [04:26<00:00, 95.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9046454767726161\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>itemid</th>\n",
       "      <th>value</th>\n",
       "      <th>valueuom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296316</th>\n",
       "      <td>11442770</td>\n",
       "      <td>28587354</td>\n",
       "      <td>30174349</td>\n",
       "      <td>2149-05-02 02:00:00</td>\n",
       "      <td>227488</td>\n",
       "      <td>10.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720600</th>\n",
       "      <td>18386668</td>\n",
       "      <td>29019639</td>\n",
       "      <td>30181943</td>\n",
       "      <td>2110-06-22 18:00:00</td>\n",
       "      <td>227488</td>\n",
       "      <td>165.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720612</th>\n",
       "      <td>18386668</td>\n",
       "      <td>29019639</td>\n",
       "      <td>30181943</td>\n",
       "      <td>2110-06-23 06:00:00</td>\n",
       "      <td>227488</td>\n",
       "      <td>600.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526886</th>\n",
       "      <td>17414351</td>\n",
       "      <td>23018977</td>\n",
       "      <td>30254621</td>\n",
       "      <td>2179-09-14 00:23:00</td>\n",
       "      <td>227488</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035626</th>\n",
       "      <td>15080981</td>\n",
       "      <td>23329122</td>\n",
       "      <td>30333231</td>\n",
       "      <td>2129-06-14 16:27:00</td>\n",
       "      <td>227488</td>\n",
       "      <td>70.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683211</th>\n",
       "      <td>13364829</td>\n",
       "      <td>26673737</td>\n",
       "      <td>39923560</td>\n",
       "      <td>2208-01-01 08:00:00</td>\n",
       "      <td>227488</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683212</th>\n",
       "      <td>13364829</td>\n",
       "      <td>26673737</td>\n",
       "      <td>39923560</td>\n",
       "      <td>2208-01-01 08:16:00</td>\n",
       "      <td>227489</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683215</th>\n",
       "      <td>13364829</td>\n",
       "      <td>26673737</td>\n",
       "      <td>39923560</td>\n",
       "      <td>2208-01-01 10:00:00</td>\n",
       "      <td>227489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683218</th>\n",
       "      <td>13364829</td>\n",
       "      <td>26673737</td>\n",
       "      <td>39923560</td>\n",
       "      <td>2208-01-01 13:00:00</td>\n",
       "      <td>227488</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683219</th>\n",
       "      <td>13364829</td>\n",
       "      <td>26673737</td>\n",
       "      <td>39923560</td>\n",
       "      <td>2208-01-01 13:04:00</td>\n",
       "      <td>227489</td>\n",
       "      <td>3050.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subject_id   hadm_id   stay_id           charttime  itemid   value  \\\n",
       "296316     11442770  28587354  30174349 2149-05-02 02:00:00  227488    10.0   \n",
       "1720600    18386668  29019639  30181943 2110-06-22 18:00:00  227488   165.0   \n",
       "1720612    18386668  29019639  30181943 2110-06-23 06:00:00  227488   600.0   \n",
       "1526886    17414351  23018977  30254621 2179-09-14 00:23:00  227488    20.0   \n",
       "1035626    15080981  23329122  30333231 2129-06-14 16:27:00  227488    70.0   \n",
       "...             ...       ...       ...                 ...     ...     ...   \n",
       "683211     13364829  26673737  39923560 2208-01-01 08:00:00  227488  3000.0   \n",
       "683212     13364829  26673737  39923560 2208-01-01 08:16:00  227489  3225.0   \n",
       "683215     13364829  26673737  39923560 2208-01-01 10:00:00  227489     0.0   \n",
       "683218     13364829  26673737  39923560 2208-01-01 13:00:00  227488  3000.0   \n",
       "683219     13364829  26673737  39923560 2208-01-01 13:04:00  227489  3050.0   \n",
       "\n",
       "        valueuom  \n",
       "296316        ml  \n",
       "1720600       ml  \n",
       "1720612       ml  \n",
       "1526886       ml  \n",
       "1035626       ml  \n",
       "...          ...  \n",
       "683211        ml  \n",
       "683212        ml  \n",
       "683215        ml  \n",
       "683218        ml  \n",
       "683219        ml  \n",
       "\n",
       "[741 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 227489 - 227488 is the real urine output\n",
    "tmp_itemid = [227488, 227489]\n",
    "\n",
    "df = df.sort_values(['stay_id', 'charttime', 'itemid'])\n",
    "\n",
    "cnt = 0\n",
    "tmp_idx = []\n",
    "for stay in tqdm(df.stay_id.unique()):\n",
    "    tmp_cond = (df.stay_id == stay) & (df.itemid.isin(tmp_itemid))\n",
    "    part_df = df.loc[tmp_cond]\n",
    "\n",
    "    for idx, ct in enumerate(part_df.charttime):\n",
    "        if len(part_df.loc[(part_df.charttime == ct)].itemid) == 2:\n",
    "            cnt += 1\n",
    "        else:\n",
    "            tmp_idx.append(part_df.index[idx])\n",
    "\n",
    "print(cnt/sum(df.itemid.isin(tmp_itemid)))\n",
    "df.loc[tmp_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main issues in irrigant out - in urine output processing\n",
    "- irrigant out and in is not recorded in the same charttime\n",
    "- irrigant out or in is recorded consecutively without each other item`s interruption\n",
    "- how to solve it?\n",
    "1. deal with the second problem by concat the information to the latest timebucket\n",
    "2. the first problem can be handled by subtacting the latest irrigant in item value from the current irrigant out value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25494/25494 [04:17<00:00, 98.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# 227489 - 227488 : step 1\n",
    "# consecutive record checking and concating\n",
    "\n",
    "drop_idx = []\n",
    "concat_data = []\n",
    "for stay in tqdm(df.stay_id.unique()):\n",
    "    tmp_cond = (df.stay_id == stay) & (df.itemid.isin(tmp_itemid))\n",
    "    part_df = df.loc[tmp_cond]\n",
    "    \n",
    "    # check for consecutiveness\n",
    "    for idx, df_idx in enumerate(part_df.index):\n",
    "        if df_idx == part_df.index[0]:\n",
    "            tmp_idx = []\n",
    "            continue\n",
    "        \n",
    "        if part_df.loc[df_idx, 'itemid'] == part_df.loc[part_df.index[idx-1], 'itemid']:\n",
    "            tmp_idx += [part_df.index[idx-1], df_idx]\n",
    "            \n",
    "        elif len(tmp_idx) != 0:\n",
    "            tmp_idx = list(set(tmp_idx))\n",
    "            drop_idx += tmp_idx\n",
    "            tmp = part_df.loc[part_df.index[idx-1]].tolist()\n",
    "            tmp[6] = sum(part_df.loc[tmp_idx, 'value'])\n",
    "            concat_data.append(tmp)\n",
    "            tmp_idx = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2050475\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>itemid</th>\n",
       "      <th>value</th>\n",
       "      <th>valueuom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>506950</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>2174-09-29 12:12:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>280.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506951</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>2174-09-29 14:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>45.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506952</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>2174-09-29 14:56:00</td>\n",
       "      <td>226627</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506953</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>2174-09-29 15:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506954</th>\n",
       "      <td>12466550</td>\n",
       "      <td>23998182</td>\n",
       "      <td>30000153</td>\n",
       "      <td>2174-09-29 16:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739035</th>\n",
       "      <td>13651601</td>\n",
       "      <td>22584645</td>\n",
       "      <td>39999230</td>\n",
       "      <td>2147-09-09 08:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>80.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739036</th>\n",
       "      <td>13651601</td>\n",
       "      <td>22584645</td>\n",
       "      <td>39999230</td>\n",
       "      <td>2147-09-09 10:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739037</th>\n",
       "      <td>13651601</td>\n",
       "      <td>22584645</td>\n",
       "      <td>39999230</td>\n",
       "      <td>2147-09-09 12:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>60.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739038</th>\n",
       "      <td>13651601</td>\n",
       "      <td>22584645</td>\n",
       "      <td>39999230</td>\n",
       "      <td>2147-09-09 14:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>80.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739039</th>\n",
       "      <td>13651601</td>\n",
       "      <td>22584645</td>\n",
       "      <td>39999230</td>\n",
       "      <td>2147-09-09 16:00:00</td>\n",
       "      <td>226559</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ml</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050176 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        subject_id   hadm_id   stay_id           charttime  itemid  value  \\\n",
       "506950    12466550  23998182  30000153 2174-09-29 12:12:00  226559  280.0   \n",
       "506951    12466550  23998182  30000153 2174-09-29 14:00:00  226559   45.0   \n",
       "506952    12466550  23998182  30000153 2174-09-29 14:56:00  226627  100.0   \n",
       "506953    12466550  23998182  30000153 2174-09-29 15:00:00  226559   50.0   \n",
       "506954    12466550  23998182  30000153 2174-09-29 16:00:00  226559   50.0   \n",
       "...            ...       ...       ...                 ...     ...    ...   \n",
       "739035    13651601  22584645  39999230 2147-09-09 08:00:00  226559   80.0   \n",
       "739036    13651601  22584645  39999230 2147-09-09 10:00:00  226559  100.0   \n",
       "739037    13651601  22584645  39999230 2147-09-09 12:00:00  226559   60.0   \n",
       "739038    13651601  22584645  39999230 2147-09-09 14:00:00  226559   80.0   \n",
       "739039    13651601  22584645  39999230 2147-09-09 16:00:00  226559  100.0   \n",
       "\n",
       "       valueuom  \n",
       "506950       ml  \n",
       "506951       ml  \n",
       "506952       ml  \n",
       "506953       ml  \n",
       "506954       ml  \n",
       "...         ...  \n",
       "739035       ml  \n",
       "739036       ml  \n",
       "739037       ml  \n",
       "739038       ml  \n",
       "739039       ml  \n",
       "\n",
       "[2050176 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape[0])\n",
    "df = pd.concat([df.drop(drop_idx), pd.DataFrame(concat_data, columns = df.columns)], axis = 0).sort_values(['stay_id', 'charttime', 'itemid'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 25494/25494 [05:10<00:00, 82.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# 227489 - 227488 : step 2\n",
    "tmp_itemid = [227488, 227489]\n",
    "\n",
    "for stay in tqdm(df.stay_id.unique()):\n",
    "    tmp_cond = (df.stay_id == stay) & (df.itemid.isin(tmp_itemid))\n",
    "    part_df = df.loc[tmp_cond]\n",
    "\n",
    "    for idx, ct in enumerate(part_df.charttime[part_df.itemid == tmp_itemid[1]]):\n",
    "        tmp_cond = (part_df.charttime == max(part_df.charttime[part_df.charttime <= ct])) & (part_df.itemid == tmp_itemid[0])\n",
    "        if sum(tmp_cond) == 0:\n",
    "            ir_in = 0\n",
    "        else:\n",
    "            ir_in = part_df.loc[tmp_cond, 'value']\n",
    "        \n",
    "        tmp_cond = (part_df.charttime == ct) & (part_df.itemid == tmp_itemid[1])\n",
    "        ir_out = part_df.loc[tmp_cond, 'value']\n",
    "        \n",
    "        tmp_cond = (df.charttime == ct) & (df.itemid == tmp_itemid[1])\n",
    "        df.loc[tmp_cond, 'value'] = ir_out - ir_in\n",
    "    \n",
    "tmp_cond = (df.itemid == 227488)\n",
    "df = df.drop(tmp_cond.index[tmp_cond]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_data/sepsis/OE_R.csv', index=False)\n",
    "# when concatenation, urine output sholud be concatenated underthe priority rule.\n",
    "# urine output from hospital should be concated when there is no urine output from icu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. procedureevents processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dirs[5])\n",
    "df.starttime = pd.to_datetime(df.starttime) # for time should be able to calculated\n",
    "df.endtime = pd.to_datetime(df.endtime) # for time should be able to calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the d_predictor, choose the item ids for labevents\n",
    "d_predictor = pd.read_csv('processed_data/sepsis/d_predictors.csv')\n",
    "tmp = [np.array(i.split(',')).astype('int').tolist() if (str(i).__contains__(',')) else [int(i)] for i in d_predictor.PE[~pd.isna(d_predictor.PE)].ravel()]\n",
    "itemids_PE = []\n",
    "for i in tmp: \n",
    "    itemids_PE += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'storetime',\n",
       "       'itemid', 'value', 'valueuom', 'location', 'locationcategory',\n",
       "       'orderid', 'linkorderid', 'ordercategoryname',\n",
       "       'ordercategorydescription', 'patientweight', 'isopenbag',\n",
       "       'continueinnextdept', 'statusdescription', 'originalamount',\n",
       "       'originalrate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369551\n",
      "16606\n"
     ]
    }
   ],
   "source": [
    "# filter data to have only predictor relevant rows and relevent columns\n",
    "tmp_cond = df.itemid.isin(itemids_PE)\n",
    "print(df.shape[0])\n",
    "df = df.loc[tmp_cond, ('subject_id', 'hadm_id', 'stay_id', 'starttime', 'endtime', 'itemid', 'value')].reset_index(drop=True)\n",
    "print(df.shape[0])# 369551 -> 16606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2220.0\n",
       "1          390.0\n",
       "2         9465.0\n",
       "3         6576.0\n",
       "4        12640.0\n",
       "          ...   \n",
       "16601     8406.0\n",
       "16602     4269.0\n",
       "16603     1381.0\n",
       "16604     1302.0\n",
       "16605      240.0\n",
       "Name: value, Length: 16606, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if df has result value that can not be type conversed to float.\n",
    "df.loc[:, 'value'].astype('float')\n",
    "# we dont have such columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: itemid, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# missing value handling \n",
    "print(df.loc[pd.isna(df.value)].itemid.value_counts())\n",
    "# no missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_data/sepsis/PE_R.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_torch_py39",
   "language": "python",
   "name": "torch_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "9934141abaf46ce0fca32690cf02266115d4467700627d173c843f0169c9d143"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
